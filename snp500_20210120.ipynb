{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snp500 20210120.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeDanielSeungjae/TransformerSNP500/blob/develop/snp500_20210120.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_UHSfYtp0xK"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import math\r\n",
        "import time\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import r2_score\r\n",
        "from sklearn.metrics import mean_squared_error as mse\r\n",
        "\r\n",
        "from IPython.display import display\r\n",
        "from IPython.display import SVG, Image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLtnSX7SzuWa",
        "outputId": "91904602-b539-42ac-d409-3a2d8a1a310f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iNYM3Vfx9pv"
      },
      "source": [
        "raw_data = pd.read_csv('./drive/MyDrive/graph/GSPC.csv')\r\n",
        "raw_data['Date'] = pd.to_datetime(raw_data['Date'])\r\n",
        "raw_data.set_index('Date',inplace=True)\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEy3VyWkBdJ"
      },
      "source": [
        "volume = 주식 거래량 \\\r\n",
        "open = 장 시작\\\r\n",
        "close = 장 마감\\\r\n",
        "high = 장중 최고거래액\\\r\n",
        "low = 장중 최저거래액"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "OgoIBWEHjCPy",
        "outputId": "a8dd2b3a-2f7b-4fa7-c875-8e1d3b650ae4"
      },
      "source": [
        "print(\"전체 데이터 shape:{}\".format(raw_data.shape))\r\n",
        "plt.figure(figsize=(25,5))\r\n",
        "plt.plot(raw_data['High'])\r\n",
        "plt.xticks(rotation=90)\r\n",
        "plt.grid(axis='x')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 shape:(1522, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFhBYEAEnudz"
      },
      "source": [
        "output_window = 5\r\n",
        "input_window = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPMthNU64OpD",
        "outputId": "316e695f-3cb7-4698-df0d-5a557f7ce675"
      },
      "source": [
        "X_cols = list(raw_data.columns)\r\n",
        "X_cols.remove('High')\r\n",
        "\r\n",
        "test_data_size = 376\r\n",
        "X = raw_data[X_cols]\r\n",
        "y = raw_data['High']\r\n",
        "\r\n",
        "print(y)\r\n",
        "\r\n",
        "scaler = StandardScaler()\r\n",
        "Xscaler = scaler.fit(X)\r\n",
        "#yscaler = scaler.fit(y.values.reshape(-1,1))\r\n",
        "\r\n",
        "X = Xscaler.transform(X)\r\n",
        "#y = yscaler.transform(y.values.reshape(-1,1))\r\n",
        "\r\n",
        "y = scaler.fit_transform(y.to_numpy().reshape(-1,1)).reshape(-1)\r\n",
        "\r\n",
        "X_train, X_test = X[:-test_data_size], X[-test_data_size:]\r\n",
        "y_train, y_test = y[:-test_data_size], y[-test_data_size:]\r\n",
        "\r\n",
        "print(\"train set :\",X_train.shape)\r\n",
        "print(\"test set :\",X_test.shape)\r\n",
        "print(\"train set : \",y_train.shape)\r\n",
        "\r\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2015-01-02    2072.360107\n",
            "2015-01-05    2054.439941\n",
            "2015-01-06    2030.250000\n",
            "2015-01-07    2029.609985\n",
            "2015-01-08    2064.080078\n",
            "                 ...     \n",
            "2021-01-12    3810.780029\n",
            "2021-01-13    3820.959961\n",
            "2021-01-14    3823.600098\n",
            "2021-01-15    3788.729980\n",
            "2021-01-19    3804.530029\n",
            "Name: High, Length: 1522, dtype: float64\n",
            "train set : (1146, 5)\n",
            "test set : (376, 5)\n",
            "train set :  (1146,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.13976164, -1.17831624, -1.23036003, ...,  0.86897423,\n",
              "        0.83603518,  0.8687158 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw70KTL0ClP_"
      },
      "source": [
        "#**seq data 형성함수**\r\n",
        ">create sequence 시퀀스를 생성한다 \\\r\n",
        " 그리고 sequence로 바꾼다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8cr0AAbCyo9"
      },
      "source": [
        "def create_sequences1(array, tw):\r\n",
        "  res = []\r\n",
        "  L = len(array)\r\n",
        "  for i in range(L - tw ):\r\n",
        "    tr_seq = np.append(array[i:i + tw][ : -output_window] , output_window*[0])\r\n",
        "    train_label = array[i:i+tw]\r\n",
        "    res.append((tr_seq, train_label))\r\n",
        "  return torch.FloatTensor(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdVqGm4mEY_v"
      },
      "source": [
        "seq_len = input_window\r\n",
        "#X_train = create_sequences1(X_train, seq_len)\r\n",
        "y_train_seq = create_sequences1(y_train, seq_len)\r\n",
        "#X_test = create_sequences1(X_test, seq_len)\r\n",
        "y_test_seq = create_sequences1(y_test, seq_len)\r\n",
        "\r\n",
        "y_train_seq = y_train_seq[:-output_window]\r\n",
        "y_test_seq = y_test_seq[:-output_window]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyB7ud40mWCE",
        "outputId": "4c2a0272-3463-40f2-89c1-d09684ad6e09"
      },
      "source": [
        "y_train_seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.1398, -1.1783, -1.2304,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [-1.1398, -1.1783, -1.2304,  ..., -1.2749, -1.2435, -1.2233]],\n",
              "\n",
              "        [[-1.1783, -1.2304, -1.2317,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [-1.1783, -1.2304, -1.2317,  ..., -1.2435, -1.2233, -1.2213]],\n",
              "\n",
              "        [[-1.2304, -1.2317, -1.1576,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [-1.2304, -1.2317, -1.1576,  ..., -1.2233, -1.2213, -1.2113]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.6921,  0.6924,  0.7079,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.6921,  0.6924,  0.7079,  ...,  0.8171,  0.8624,  0.8610]],\n",
              "\n",
              "        [[ 0.6924,  0.7079,  0.6994,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.6924,  0.7079,  0.6994,  ...,  0.8624,  0.8610,  0.8860]],\n",
              "\n",
              "        [[ 0.7079,  0.6994,  0.6850,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.7079,  0.6994,  0.6850,  ...,  0.8610,  0.8860,  0.8943]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcxThjJ6FNqt"
      },
      "source": [
        ">예시\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iFJwllxWQy2"
      },
      "source": [
        "예시의 create_inout_sequences 역할과 비슷"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWlekQSKaykK",
        "outputId": "df7b5c36-ace3-4397-95f4-bac5f49b6fd1"
      },
      "source": [
        "#print(\"X_train :\",(X_train.shape))\r\n",
        "#print(\"X_test :\",(X_test.shape))\r\n",
        "print(\"y_train :\",(y_train_seq.shape))\r\n",
        "print(\"y_test :\",(y_test_seq.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train : torch.Size([941, 2, 200])\n",
            "y_test : torch.Size([171, 2, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQq4wBKxeNCv"
      },
      "source": [
        "**MODEL 정의하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRc7tiXqKoro"
      },
      "source": [
        "class TransformerModel(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, ninp = 250, nlayers=1, dropout=0.1):\r\n",
        "    super(TransformerModel, self).__init__()\r\n",
        "\r\n",
        "    from torch.nn import TransformerEncoder, TransformerEncoderLayer\r\n",
        "    \r\n",
        "    self.model_type = 'Transformer'\r\n",
        "    \r\n",
        "    self.src_mask = None\r\n",
        "    \r\n",
        "    self.pos_encoder = PositionalEncoding(ninp)\r\n",
        "    self.encoder_layers = TransformerEncoderLayer(d_model = ninp, nhead = 10, dropout = dropout)\r\n",
        "    self.transformer_encoder = TransformerEncoder(self.encoder_layers, num_layers = nlayers)\r\n",
        "    #self.encoder = nn.Embedding(ntoken, ninp) #시계열에서 불필요?\r\n",
        "    self.decoder = nn.Linear(ninp, 1)\r\n",
        "\r\n",
        "    self.init_weights()\r\n",
        "\r\n",
        "  def _generate_square_subsequent_mask(self, sz):\r\n",
        "    mask = (torch.triu(torch.ones(sz,sz))==1).transpose(0,1)\r\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\r\n",
        "    return mask\r\n",
        "\r\n",
        "  def init_weights(self):\r\n",
        "    initrange = 0.1\r\n",
        "    self.decoder.bias.data.zero_()\r\n",
        "    self.decoder.weight.data.uniform_(-initrange, initrange)\r\n",
        "\r\n",
        "  def forward(self, src):\r\n",
        "    if self.src_mask is None or self.src_mask.size(0) != len(src):\r\n",
        "      device = src.device\r\n",
        "      mask = self._generate_square_subsequent_mask(len(src)).to(device)\r\n",
        "      self.src_mask = mask\r\n",
        "    src = self.pos_encoder(src)\r\n",
        "    output = self.transformer_encoder(src, self.src_mask)\r\n",
        "    output = self.decoder(output)\r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-tHvuma3K6r"
      },
      "source": [
        "**Positional Encoing**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA5KYYXG3Jjl"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\r\n",
        "  def __init__(self, d_model, max_len=5000):\r\n",
        "    super(PositionalEncoding, self).__init__()\r\n",
        "\r\n",
        "    pe = torch.zeros(max_len, d_model)\r\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\r\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\r\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\r\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\r\n",
        "    pe = pe.unsqueeze(0).transpose(0,1)\r\n",
        "    self.register_buffer('pe',pe)\r\n",
        "  \r\n",
        "  def forward(self,x):\r\n",
        "    return x + self.pe[:x.size(0), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5y8LWhuX-mN"
      },
      "source": [
        "def get_batch(source, i, batch_size):\r\n",
        "  length = min(batch_size, len(source) - 1 - i)\r\n",
        "  data = source[i:i+length]\r\n",
        "  input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) #1은 feature size\r\n",
        "  target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\r\n",
        "  return input, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74_1RqwrbPPO"
      },
      "source": [
        "#**Train 생성하기**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lF5n-X5gjag"
      },
      "source": [
        "def plot_and_loss(eval_model, data_source, epoch):\r\n",
        "  eval_model.eval()\r\n",
        "  total_loss = 0.\r\n",
        "  test_result = torch.Tensor(0)\r\n",
        "  truth = torch.Tensor(0)\r\n",
        "  with torch.no_grad():\r\n",
        "    for i in range(0,len(data_source) - 1):\r\n",
        "      daat, target = get_batch(data_source, i, 1)\r\n",
        "      output = eval_model(daat)\r\n",
        "\r\n",
        "      total_loss += criterion(output[-output_window:],target[-output_window:]).item()\r\n",
        "\r\n",
        "      test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0)\r\n",
        "      truth = torch.cat((truth, target[-1].view(-1).cpu()),0)\r\n",
        "  \r\n",
        "  len(test_result)\r\n",
        "  print(test_result)\r\n",
        "  plt.plot(test_result, color = \"red\")\r\n",
        "  plt.plot(truth[:50],color=\"blue\")\r\n",
        "  plt.plot(test_result-truth, color=\"green\")\r\n",
        "  plt.grid(True, which='both')\r\n",
        "  plt.axhline(y=0,color='k')\r\n",
        "  plt.savefig(\"./drive/MyDrive/graph/transformer-epoch%d.png\"%epoch)\r\n",
        "  plt.close()\r\n",
        "\r\n",
        "  return total_loss / i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LO2NmBN4E2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d38eaff-fb21-4d72-e9db-762144afee90"
      },
      "source": [
        "\r\n",
        "batch_size = 40\r\n",
        "\r\n",
        "\r\n",
        "def train(train_data):\r\n",
        "  \r\n",
        "  model.train() #학습모드 시작\r\n",
        "  total_loss = 0. #total loss 초기화\r\n",
        "  start_time = time.time() \r\n",
        "  \r\n",
        "  for batch, i in enumerate(range(0, len(train_data) - 1,batch_size)):\r\n",
        "    \r\n",
        "    data, targets = get_batch(train_data, i, batch_size)\r\n",
        "    \r\n",
        "    optimizer.zero_grad()\r\n",
        "    \r\n",
        "    output = model(data)\r\n",
        "        \r\n",
        "    loss = criterion(output[-output_window:], targets[-output_window:])\r\n",
        "    \r\n",
        "    loss.backward()\r\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),0.5)\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    total_loss += loss.item()\r\n",
        "    log_interval = int(len(train_data) / batch_size / 5)\r\n",
        "    if batch % log_interval == 0 and batch > 0:\r\n",
        "      cur_loss = total_loss / log_interval\r\n",
        "      elapsed = time.time() - start_time\r\n",
        "      print('| epoch {:3d} | {:5d}/{:5d} batches |'\r\n",
        "        'lr {:02.6f} | ms/batch {:5.2f} | '\r\n",
        "        'loss {:5.5f} | ppl {:8.2f}'.format\r\n",
        "        (epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\r\n",
        "        elapsed*1000 / log_interval,\r\n",
        "        cur_loss, math.exp(cur_loss)))\r\n",
        "      total_loss = 0\r\n",
        "      start_time = time.time()\r\n",
        "\r\n",
        "def evaluate(eval_model, data_source):\r\n",
        "  eval_model.eval()\r\n",
        "  total_loss = 0.\r\n",
        "  eval_batch_size = 1000\r\n",
        "  with torch.no_grad():\r\n",
        "    for i in range(0, len(data_source) - 1, eval_batch_size):\r\n",
        "      data, targets = get_batch(data_source, i, eval_batch_size)\r\n",
        "      output = eval_model(data)\r\n",
        "      total_loss += len(data[0])*criterion(output[-output_window:], targets[-output_window:]).cpu().item()\r\n",
        "  return total_loss/len(data_source)\r\n",
        "\r\n",
        "def predict(eval_model, data_source, steps):\r\n",
        "  eval_model.eval()\r\n",
        "  total_loss = 0.\r\n",
        "  test_results = torch.Tensor(0)\r\n",
        "  truth = torch.Tensor(0)\r\n",
        "  _, data = get_batch(data_source, 0,1)\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    for i in range(0, steps, 1):\r\n",
        "      \r\n",
        "      input = torch.clone(data[-input_window:])\r\n",
        "      input[-output_window:] = 0\r\n",
        "\r\n",
        "      output = eval_model(data[-input_window:])\r\n",
        "      data = torch.cat((data, output[-1:]))\r\n",
        "\r\n",
        "  data = data.cpu().view(-1)\r\n",
        "\r\n",
        "  plt.plot(data, color=\"red\")\r\n",
        "  plt.plot(data[:input_window],color=\"blue\")\r\n",
        "  plt.grid(True, which='both')\r\n",
        "  plt.axhline(y=0, color='k')\r\n",
        "  plt.savefig('./drive/MyDrive/graph/transformer-future%d.png'%steps)\r\n",
        "  plt.close()\r\n",
        "\r\n",
        "model = TransformerModel().to(device)\r\n",
        "train_data = y_train_seq.to(device)\r\n",
        "val_data = y_test_seq.to(device)\r\n",
        "\r\n",
        "criterion = nn.MSELoss()\r\n",
        "lr = 0.005\r\n",
        "optimizer= torch.optim.AdamW(model.parameters(),lr=lr)\r\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma = 0.95)\r\n",
        "\r\n",
        "best_val_loss = float(\"inf\")\r\n",
        "epochs = 100\r\n",
        "best_model = None\r\n",
        "\r\n",
        "for epoch in range(1, epochs + 1):\r\n",
        "  epoch_start_time = time.time()\r\n",
        "  train(train_data)\r\n",
        "\r\n",
        "  if(epoch % 10 is 0):\r\n",
        "    val_loss = plot_and_loss(model, val_data, epoch)\r\n",
        "    predict(model, val_data, 100)\r\n",
        "  else:\r\n",
        "    val_loss = evaluate(model, val_data)\r\n",
        "  \r\n",
        "  ppl=0.0\r\n",
        "  try:\r\n",
        "    ppl = math.exp(val_loss)\r\n",
        "  except OverflowError:\r\n",
        "    ppl = float('inf')\r\n",
        "\r\n",
        "  print('-' * 89)\r\n",
        "  print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\r\n",
        "                          val_loss, ppl))\r\n",
        "  print('-' * 89)\r\n",
        "  scheduler.step()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |     4/   23 batches |lr 0.005000 | ms/batch 61.51 | loss 53.11414 | ppl 116729324596259228483584.00\n",
            "| epoch   1 |     8/   23 batches |lr 0.005000 | ms/batch 33.50 | loss 1.57878 | ppl     4.85\n",
            "| epoch   1 |    12/   23 batches |lr 0.005000 | ms/batch 34.90 | loss 0.21799 | ppl     1.24\n",
            "| epoch   1 |    16/   23 batches |lr 0.005000 | ms/batch 34.29 | loss 2.89985 | ppl    18.17\n",
            "| epoch   1 |    20/   23 batches |lr 0.005000 | ms/batch 35.42 | loss 0.66175 | ppl     1.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  0.94s | valid loss 2.53022 | valid ppl    12.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |     4/   23 batches |lr 0.004513 | ms/batch 43.07 | loss 1.14520 | ppl     3.14\n",
            "| epoch   2 |     8/   23 batches |lr 0.004513 | ms/batch 33.78 | loss 0.63660 | ppl     1.89\n",
            "| epoch   2 |    12/   23 batches |lr 0.004513 | ms/batch 34.44 | loss 0.86538 | ppl     2.38\n",
            "| epoch   2 |    16/   23 batches |lr 0.004513 | ms/batch 34.73 | loss 0.19466 | ppl     1.21\n",
            "| epoch   2 |    20/   23 batches |lr 0.004513 | ms/batch 34.63 | loss 0.29222 | ppl     1.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  0.86s | valid loss 2.13766 | valid ppl     8.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |     4/   23 batches |lr 0.004287 | ms/batch 48.05 | loss 1.30748 | ppl     3.70\n",
            "| epoch   3 |     8/   23 batches |lr 0.004287 | ms/batch 36.47 | loss 0.87703 | ppl     2.40\n",
            "| epoch   3 |    12/   23 batches |lr 0.004287 | ms/batch 35.70 | loss 1.83972 | ppl     6.29\n",
            "| epoch   3 |    16/   23 batches |lr 0.004287 | ms/batch 35.74 | loss 1.05593 | ppl     2.87\n",
            "| epoch   3 |    20/   23 batches |lr 0.004287 | ms/batch 35.84 | loss 0.98797 | ppl     2.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  0.91s | valid loss 0.52402 | valid ppl     1.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |     4/   23 batches |lr 0.004073 | ms/batch 45.86 | loss 11.16187 | ppl 70394.56\n",
            "| epoch   4 |     8/   23 batches |lr 0.004073 | ms/batch 35.65 | loss 2.33258 | ppl    10.30\n",
            "| epoch   4 |    12/   23 batches |lr 0.004073 | ms/batch 35.82 | loss 0.66512 | ppl     1.94\n",
            "| epoch   4 |    16/   23 batches |lr 0.004073 | ms/batch 35.68 | loss 2.64168 | ppl    14.04\n",
            "| epoch   4 |    20/   23 batches |lr 0.004073 | ms/batch 36.77 | loss 0.47168 | ppl     1.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  0.91s | valid loss 1.01232 | valid ppl     2.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |     4/   23 batches |lr 0.003869 | ms/batch 46.55 | loss 5.54389 | ppl   255.67\n",
            "| epoch   5 |     8/   23 batches |lr 0.003869 | ms/batch 36.18 | loss 2.40820 | ppl    11.11\n",
            "| epoch   5 |    12/   23 batches |lr 0.003869 | ms/batch 36.11 | loss 0.23211 | ppl     1.26\n",
            "| epoch   5 |    16/   23 batches |lr 0.003869 | ms/batch 36.18 | loss 0.86305 | ppl     2.37\n",
            "| epoch   5 |    20/   23 batches |lr 0.003869 | ms/batch 36.11 | loss 0.67276 | ppl     1.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  0.91s | valid loss 0.61425 | valid ppl     1.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |     4/   23 batches |lr 0.003675 | ms/batch 44.22 | loss 2.89919 | ppl    18.16\n",
            "| epoch   6 |     8/   23 batches |lr 0.003675 | ms/batch 33.91 | loss 0.65858 | ppl     1.93\n",
            "| epoch   6 |    12/   23 batches |lr 0.003675 | ms/batch 34.97 | loss 0.24021 | ppl     1.27\n",
            "| epoch   6 |    16/   23 batches |lr 0.003675 | ms/batch 34.05 | loss 0.20267 | ppl     1.22\n",
            "| epoch   6 |    20/   23 batches |lr 0.003675 | ms/batch 34.40 | loss 0.25458 | ppl     1.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  0.86s | valid loss 2.17082 | valid ppl     8.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |     4/   23 batches |lr 0.003492 | ms/batch 44.39 | loss 0.82702 | ppl     2.29\n",
            "| epoch   7 |     8/   23 batches |lr 0.003492 | ms/batch 34.10 | loss 0.14554 | ppl     1.16\n",
            "| epoch   7 |    12/   23 batches |lr 0.003492 | ms/batch 34.37 | loss 0.39966 | ppl     1.49\n",
            "| epoch   7 |    16/   23 batches |lr 0.003492 | ms/batch 34.26 | loss 0.18696 | ppl     1.21\n",
            "| epoch   7 |    20/   23 batches |lr 0.003492 | ms/batch 34.20 | loss 0.04890 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time:  0.86s | valid loss 2.24350 | valid ppl     9.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |     4/   23 batches |lr 0.003317 | ms/batch 43.52 | loss 1.31037 | ppl     3.71\n",
            "| epoch   8 |     8/   23 batches |lr 0.003317 | ms/batch 34.54 | loss 0.14958 | ppl     1.16\n",
            "| epoch   8 |    12/   23 batches |lr 0.003317 | ms/batch 34.62 | loss 0.25286 | ppl     1.29\n",
            "| epoch   8 |    16/   23 batches |lr 0.003317 | ms/batch 34.34 | loss 0.34430 | ppl     1.41\n",
            "| epoch   8 |    20/   23 batches |lr 0.003317 | ms/batch 34.14 | loss 0.21799 | ppl     1.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time:  0.86s | valid loss 1.08825 | valid ppl     2.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |     4/   23 batches |lr 0.003151 | ms/batch 44.35 | loss 0.78488 | ppl     2.19\n",
            "| epoch   9 |     8/   23 batches |lr 0.003151 | ms/batch 34.19 | loss 0.09070 | ppl     1.09\n",
            "| epoch   9 |    12/   23 batches |lr 0.003151 | ms/batch 36.34 | loss 0.08450 | ppl     1.09\n",
            "| epoch   9 |    16/   23 batches |lr 0.003151 | ms/batch 34.91 | loss 0.11238 | ppl     1.12\n",
            "| epoch   9 |    20/   23 batches |lr 0.003151 | ms/batch 34.10 | loss 0.14656 | ppl     1.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time:  0.87s | valid loss 0.87460 | valid ppl     2.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |     4/   23 batches |lr 0.002994 | ms/batch 44.26 | loss 0.37280 | ppl     1.45\n",
            "| epoch  10 |     8/   23 batches |lr 0.002994 | ms/batch 33.98 | loss 0.23509 | ppl     1.27\n",
            "| epoch  10 |    12/   23 batches |lr 0.002994 | ms/batch 34.18 | loss 0.06444 | ppl     1.07\n",
            "| epoch  10 |    16/   23 batches |lr 0.002994 | ms/batch 34.21 | loss 0.07252 | ppl     1.08\n",
            "| epoch  10 |    20/   23 batches |lr 0.002994 | ms/batch 35.82 | loss 0.08485 | ppl     1.09\n",
            "tensor([0.3761, 0.3797, 0.3827, 0.3870, 0.3889, 0.3936, 0.3944, 0.3936, 0.3923,\n",
            "        0.3905, 0.3859, 0.3814, 0.3819, 0.3851, 0.3839, 0.3843, 0.3828, 0.3848,\n",
            "        0.3825, 0.3806, 0.3814, 0.3829, 0.3841, 0.3843, 0.3842, 0.3848, 0.3818,\n",
            "        0.3811, 0.3816, 0.3844, 0.3906, 0.3995, 0.4010, 0.4003, 0.3960, 0.3849,\n",
            "        0.3806, 0.3811, 0.3826, 0.3849, 0.3827, 0.3795, 0.3754, 0.3742, 0.3730,\n",
            "        0.3726, 0.3723, 0.3738, 0.3738, 0.3764, 0.3755, 0.3760, 0.3749, 0.3754,\n",
            "        0.3760, 0.3762, 0.3785, 0.3818, 0.3860, 0.3901, 0.3911, 0.3904, 0.3878,\n",
            "        0.3843, 0.3836, 0.3845, 0.3877, 0.3862, 0.3856, 0.3864, 0.3867, 0.3887,\n",
            "        0.3874, 0.3855, 0.3838, 0.3828, 0.3854, 0.3880, 0.3920, 0.3937, 0.3938,\n",
            "        0.3933, 0.3928, 0.3887, 0.3905, 0.3899, 0.3896, 0.3899, 0.3908, 0.3915,\n",
            "        0.3934, 0.3958, 0.3964, 0.3958, 0.3961, 0.3973, 0.3984, 0.3992, 0.4000,\n",
            "        0.4006, 0.4006, 0.4004, 0.4003, 0.4010, 0.4009, 0.4015, 0.4017, 0.4022,\n",
            "        0.4026, 0.4031, 0.4033, 0.4027, 0.4030, 0.4035, 0.4036, 0.4038, 0.4039,\n",
            "        0.4039, 0.4043, 0.4035, 0.4037, 0.4036, 0.4042, 0.4041, 0.4034, 0.4036,\n",
            "        0.4036, 0.4042, 0.4045, 0.4046, 0.4041, 0.4043, 0.4039, 0.4025, 0.3950,\n",
            "        0.3968, 0.3973, 0.3985, 0.3984, 0.3912, 0.3872, 0.3873, 0.3832, 0.3776,\n",
            "        0.3780, 0.3725, 0.3750, 0.3713, 0.3649, 0.3504, 0.3440, 0.3512, 0.3438,\n",
            "        0.3499, 0.3373, 0.3380, 0.3314, 0.3221, 0.3255, 0.3220, 0.3326, 0.3408,\n",
            "        0.3456, 0.3561, 0.3572, 0.3613, 0.3526, 0.3559, 0.3710, 0.3757])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time:  1.57s | valid loss 1.84606 | valid ppl     6.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |     4/   23 batches |lr 0.002844 | ms/batch 42.57 | loss 1.52845 | ppl     4.61\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  11 |     8/   23 batches |lr 0.002844 | ms/batch 34.32 | loss 0.20031 | ppl     1.22\n",
            "| epoch  11 |    12/   23 batches |lr 0.002844 | ms/batch 34.19 | loss 0.17710 | ppl     1.19\n",
            "| epoch  11 |    16/   23 batches |lr 0.002844 | ms/batch 34.38 | loss 0.29004 | ppl     1.34\n",
            "| epoch  11 |    20/   23 batches |lr 0.002844 | ms/batch 34.21 | loss 0.07388 | ppl     1.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time:  0.86s | valid loss 1.53893 | valid ppl     4.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |     4/   23 batches |lr 0.002702 | ms/batch 43.45 | loss 1.72686 | ppl     5.62\n",
            "| epoch  12 |     8/   23 batches |lr 0.002702 | ms/batch 35.23 | loss 0.22058 | ppl     1.25\n",
            "| epoch  12 |    12/   23 batches |lr 0.002702 | ms/batch 34.00 | loss 0.17403 | ppl     1.19\n",
            "| epoch  12 |    16/   23 batches |lr 0.002702 | ms/batch 34.51 | loss 0.45019 | ppl     1.57\n",
            "| epoch  12 |    20/   23 batches |lr 0.002702 | ms/batch 33.94 | loss 0.11905 | ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time:  0.86s | valid loss 2.92765 | valid ppl    18.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |     4/   23 batches |lr 0.002567 | ms/batch 43.90 | loss 1.02958 | ppl     2.80\n",
            "| epoch  13 |     8/   23 batches |lr 0.002567 | ms/batch 35.71 | loss 0.12855 | ppl     1.14\n",
            "| epoch  13 |    12/   23 batches |lr 0.002567 | ms/batch 36.51 | loss 0.15558 | ppl     1.17\n",
            "| epoch  13 |    16/   23 batches |lr 0.002567 | ms/batch 34.35 | loss 0.11342 | ppl     1.12\n",
            "| epoch  13 |    20/   23 batches |lr 0.002567 | ms/batch 34.58 | loss 0.13446 | ppl     1.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time:  0.88s | valid loss 1.21504 | valid ppl     3.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |     4/   23 batches |lr 0.002438 | ms/batch 43.40 | loss 0.76468 | ppl     2.15\n",
            "| epoch  14 |     8/   23 batches |lr 0.002438 | ms/batch 34.77 | loss 0.06913 | ppl     1.07\n",
            "| epoch  14 |    12/   23 batches |lr 0.002438 | ms/batch 34.66 | loss 0.19188 | ppl     1.21\n",
            "| epoch  14 |    16/   23 batches |lr 0.002438 | ms/batch 34.43 | loss 0.07102 | ppl     1.07\n",
            "| epoch  14 |    20/   23 batches |lr 0.002438 | ms/batch 34.23 | loss 0.07053 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time:  0.86s | valid loss 2.30901 | valid ppl    10.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |     4/   23 batches |lr 0.002316 | ms/batch 44.27 | loss 0.32032 | ppl     1.38\n",
            "| epoch  15 |     8/   23 batches |lr 0.002316 | ms/batch 34.15 | loss 0.07164 | ppl     1.07\n",
            "| epoch  15 |    12/   23 batches |lr 0.002316 | ms/batch 34.08 | loss 0.37625 | ppl     1.46\n",
            "| epoch  15 |    16/   23 batches |lr 0.002316 | ms/batch 34.19 | loss 0.09926 | ppl     1.10\n",
            "| epoch  15 |    20/   23 batches |lr 0.002316 | ms/batch 35.48 | loss 0.07955 | ppl     1.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time:  0.86s | valid loss 1.56703 | valid ppl     4.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |     4/   23 batches |lr 0.002201 | ms/batch 43.48 | loss 0.41173 | ppl     1.51\n",
            "| epoch  16 |     8/   23 batches |lr 0.002201 | ms/batch 34.01 | loss 0.07145 | ppl     1.07\n",
            "| epoch  16 |    12/   23 batches |lr 0.002201 | ms/batch 35.13 | loss 0.17853 | ppl     1.20\n",
            "| epoch  16 |    16/   23 batches |lr 0.002201 | ms/batch 34.37 | loss 0.03558 | ppl     1.04\n",
            "| epoch  16 |    20/   23 batches |lr 0.002201 | ms/batch 34.74 | loss 0.05602 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time:  0.87s | valid loss 2.18204 | valid ppl     8.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |     4/   23 batches |lr 0.002091 | ms/batch 43.59 | loss 0.23743 | ppl     1.27\n",
            "| epoch  17 |     8/   23 batches |lr 0.002091 | ms/batch 34.14 | loss 0.04015 | ppl     1.04\n",
            "| epoch  17 |    12/   23 batches |lr 0.002091 | ms/batch 34.52 | loss 0.08158 | ppl     1.09\n",
            "| epoch  17 |    16/   23 batches |lr 0.002091 | ms/batch 34.60 | loss 0.04484 | ppl     1.05\n",
            "| epoch  17 |    20/   23 batches |lr 0.002091 | ms/batch 34.39 | loss 0.12324 | ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time:  0.87s | valid loss 1.28031 | valid ppl     3.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |     4/   23 batches |lr 0.001986 | ms/batch 45.16 | loss 0.38427 | ppl     1.47\n",
            "| epoch  18 |     8/   23 batches |lr 0.001986 | ms/batch 34.22 | loss 0.07392 | ppl     1.08\n",
            "| epoch  18 |    12/   23 batches |lr 0.001986 | ms/batch 34.24 | loss 0.10511 | ppl     1.11\n",
            "| epoch  18 |    16/   23 batches |lr 0.001986 | ms/batch 35.32 | loss 0.02586 | ppl     1.03\n",
            "| epoch  18 |    20/   23 batches |lr 0.001986 | ms/batch 34.36 | loss 0.06252 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time:  0.87s | valid loss 2.02173 | valid ppl     7.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |     4/   23 batches |lr 0.001887 | ms/batch 43.95 | loss 0.66660 | ppl     1.95\n",
            "| epoch  19 |     8/   23 batches |lr 0.001887 | ms/batch 35.51 | loss 0.06957 | ppl     1.07\n",
            "| epoch  19 |    12/   23 batches |lr 0.001887 | ms/batch 34.15 | loss 0.12447 | ppl     1.13\n",
            "| epoch  19 |    16/   23 batches |lr 0.001887 | ms/batch 34.63 | loss 0.04138 | ppl     1.04\n",
            "| epoch  19 |    20/   23 batches |lr 0.001887 | ms/batch 35.74 | loss 0.08328 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time:  0.88s | valid loss 1.57672 | valid ppl     4.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |     4/   23 batches |lr 0.001792 | ms/batch 47.89 | loss 0.32004 | ppl     1.38\n",
            "| epoch  20 |     8/   23 batches |lr 0.001792 | ms/batch 36.38 | loss 0.06378 | ppl     1.07\n",
            "| epoch  20 |    12/   23 batches |lr 0.001792 | ms/batch 34.22 | loss 0.14612 | ppl     1.16\n",
            "| epoch  20 |    16/   23 batches |lr 0.001792 | ms/batch 34.23 | loss 0.03412 | ppl     1.03\n",
            "| epoch  20 |    20/   23 batches |lr 0.001792 | ms/batch 36.68 | loss 0.05605 | ppl     1.06\n",
            "tensor([0.2705, 0.2723, 0.2741, 0.2742, 0.2763, 0.2781, 0.2695, 0.2700, 0.2683,\n",
            "        0.2711, 0.2728, 0.2737, 0.2771, 0.2802, 0.2777, 0.2787, 0.2739, 0.2794,\n",
            "        0.2809, 0.2812, 0.2831, 0.2851, 0.2873, 0.2907, 0.2888, 0.2887, 0.2912,\n",
            "        0.2913, 0.2916, 0.2918, 0.2919, 0.2934, 0.2883, 0.2861, 0.2898, 0.2890,\n",
            "        0.2874, 0.2875, 0.2889, 0.2924, 0.2855, 0.2871, 0.2865, 0.2870, 0.2865,\n",
            "        0.2873, 0.2874, 0.2899, 0.2908, 0.2955, 0.2955, 0.2981, 0.2971, 0.2976,\n",
            "        0.2991, 0.2998, 0.2999, 0.3002, 0.3031, 0.3038, 0.3044, 0.3051, 0.3057,\n",
            "        0.3069, 0.3089, 0.3114, 0.3129, 0.3121, 0.3123, 0.3126, 0.3132, 0.3146,\n",
            "        0.3157, 0.3154, 0.3171, 0.3139, 0.3146, 0.3142, 0.3164, 0.3170, 0.3250,\n",
            "        0.3239, 0.3112, 0.3068, 0.3080, 0.3057, 0.3063, 0.3025, 0.3045, 0.3044,\n",
            "        0.3052, 0.3058, 0.3078, 0.3070, 0.3070, 0.3091, 0.3103, 0.3113, 0.3123,\n",
            "        0.3142, 0.3148, 0.3152, 0.3151, 0.3161, 0.3151, 0.3164, 0.3162, 0.3171,\n",
            "        0.3180, 0.3191, 0.3203, 0.3181, 0.3197, 0.3209, 0.3233, 0.3233, 0.3235,\n",
            "        0.3239, 0.3264, 0.3220, 0.3225, 0.3212, 0.3229, 0.3232, 0.3222, 0.3230,\n",
            "        0.3230, 0.3249, 0.3253, 0.3248, 0.3220, 0.3225, 0.3222, 0.3170, 0.3073,\n",
            "        0.3140, 0.3162, 0.3154, 0.3076, 0.3016, 0.2902, 0.2883, 0.2658, 0.2609,\n",
            "        0.2599, 0.2577, 0.2625, 0.2490, 0.2406, 0.2268, 0.2122, 0.2154, 0.2122,\n",
            "        0.2091, 0.1999, 0.1927, 0.1911, 0.1750, 0.1695, 0.1691, 0.1878, 0.2001,\n",
            "        0.2090, 0.2226, 0.2193, 0.2188, 0.2150, 0.2092, 0.2238, 0.2289])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time:  1.60s | valid loss 2.10490 | valid ppl     8.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |     4/   23 batches |lr 0.001703 | ms/batch 42.51 | loss 0.16129 | ppl     1.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  21 |     8/   23 batches |lr 0.001703 | ms/batch 34.41 | loss 0.06472 | ppl     1.07\n",
            "| epoch  21 |    12/   23 batches |lr 0.001703 | ms/batch 34.39 | loss 0.10941 | ppl     1.12\n",
            "| epoch  21 |    16/   23 batches |lr 0.001703 | ms/batch 35.64 | loss 0.02875 | ppl     1.03\n",
            "| epoch  21 |    20/   23 batches |lr 0.001703 | ms/batch 35.99 | loss 0.08644 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time:  0.87s | valid loss 1.46136 | valid ppl     4.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |     4/   23 batches |lr 0.001618 | ms/batch 46.48 | loss 0.53515 | ppl     1.71\n",
            "| epoch  22 |     8/   23 batches |lr 0.001618 | ms/batch 34.30 | loss 0.06693 | ppl     1.07\n",
            "| epoch  22 |    12/   23 batches |lr 0.001618 | ms/batch 34.57 | loss 0.04498 | ppl     1.05\n",
            "| epoch  22 |    16/   23 batches |lr 0.001618 | ms/batch 34.65 | loss 0.03939 | ppl     1.04\n",
            "| epoch  22 |    20/   23 batches |lr 0.001618 | ms/batch 34.18 | loss 0.05189 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time:  0.88s | valid loss 2.03910 | valid ppl     7.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |     4/   23 batches |lr 0.001537 | ms/batch 44.40 | loss 0.11304 | ppl     1.12\n",
            "| epoch  23 |     8/   23 batches |lr 0.001537 | ms/batch 34.47 | loss 0.06772 | ppl     1.07\n",
            "| epoch  23 |    12/   23 batches |lr 0.001537 | ms/batch 34.55 | loss 0.14188 | ppl     1.15\n",
            "| epoch  23 |    16/   23 batches |lr 0.001537 | ms/batch 34.22 | loss 0.07081 | ppl     1.07\n",
            "| epoch  23 |    20/   23 batches |lr 0.001537 | ms/batch 34.49 | loss 0.08775 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time:  0.87s | valid loss 1.43636 | valid ppl     4.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |     4/   23 batches |lr 0.001460 | ms/batch 44.09 | loss 0.34118 | ppl     1.41\n",
            "| epoch  24 |     8/   23 batches |lr 0.001460 | ms/batch 35.06 | loss 0.03443 | ppl     1.04\n",
            "| epoch  24 |    12/   23 batches |lr 0.001460 | ms/batch 34.50 | loss 0.03578 | ppl     1.04\n",
            "| epoch  24 |    16/   23 batches |lr 0.001460 | ms/batch 34.57 | loss 0.12916 | ppl     1.14\n",
            "| epoch  24 |    20/   23 batches |lr 0.001460 | ms/batch 34.36 | loss 0.09122 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time:  0.87s | valid loss 1.89429 | valid ppl     6.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |     4/   23 batches |lr 0.001387 | ms/batch 45.14 | loss 0.04773 | ppl     1.05\n",
            "| epoch  25 |     8/   23 batches |lr 0.001387 | ms/batch 35.21 | loss 0.08894 | ppl     1.09\n",
            "| epoch  25 |    12/   23 batches |lr 0.001387 | ms/batch 34.87 | loss 0.11123 | ppl     1.12\n",
            "| epoch  25 |    16/   23 batches |lr 0.001387 | ms/batch 34.36 | loss 0.03930 | ppl     1.04\n",
            "| epoch  25 |    20/   23 batches |lr 0.001387 | ms/batch 34.64 | loss 0.06838 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time:  0.87s | valid loss 1.57955 | valid ppl     4.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |     4/   23 batches |lr 0.001318 | ms/batch 43.80 | loss 0.52177 | ppl     1.69\n",
            "| epoch  26 |     8/   23 batches |lr 0.001318 | ms/batch 36.22 | loss 0.06464 | ppl     1.07\n",
            "| epoch  26 |    12/   23 batches |lr 0.001318 | ms/batch 36.38 | loss 0.01363 | ppl     1.01\n",
            "| epoch  26 |    16/   23 batches |lr 0.001318 | ms/batch 34.77 | loss 0.06742 | ppl     1.07\n",
            "| epoch  26 |    20/   23 batches |lr 0.001318 | ms/batch 34.32 | loss 0.05589 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time:  0.88s | valid loss 1.99749 | valid ppl     7.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |     4/   23 batches |lr 0.001252 | ms/batch 46.40 | loss 0.04457 | ppl     1.05\n",
            "| epoch  27 |     8/   23 batches |lr 0.001252 | ms/batch 36.06 | loss 0.08796 | ppl     1.09\n",
            "| epoch  27 |    12/   23 batches |lr 0.001252 | ms/batch 36.47 | loss 0.07229 | ppl     1.07\n",
            "| epoch  27 |    16/   23 batches |lr 0.001252 | ms/batch 34.80 | loss 0.03813 | ppl     1.04\n",
            "| epoch  27 |    20/   23 batches |lr 0.001252 | ms/batch 37.04 | loss 0.07108 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time:  0.91s | valid loss 1.51452 | valid ppl     4.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |     4/   23 batches |lr 0.001189 | ms/batch 46.69 | loss 0.75448 | ppl     2.13\n",
            "| epoch  28 |     8/   23 batches |lr 0.001189 | ms/batch 36.36 | loss 0.14501 | ppl     1.16\n",
            "| epoch  28 |    12/   23 batches |lr 0.001189 | ms/batch 36.40 | loss 0.03729 | ppl     1.04\n",
            "| epoch  28 |    16/   23 batches |lr 0.001189 | ms/batch 35.88 | loss 0.02930 | ppl     1.03\n",
            "| epoch  28 |    20/   23 batches |lr 0.001189 | ms/batch 35.17 | loss 0.06818 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time:  0.90s | valid loss 1.71471 | valid ppl     5.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |     4/   23 batches |lr 0.001130 | ms/batch 45.24 | loss 0.05590 | ppl     1.06\n",
            "| epoch  29 |     8/   23 batches |lr 0.001130 | ms/batch 34.60 | loss 0.18986 | ppl     1.21\n",
            "| epoch  29 |    12/   23 batches |lr 0.001130 | ms/batch 34.28 | loss 0.36410 | ppl     1.44\n",
            "| epoch  29 |    16/   23 batches |lr 0.001130 | ms/batch 34.51 | loss 0.07162 | ppl     1.07\n",
            "| epoch  29 |    20/   23 batches |lr 0.001130 | ms/batch 36.04 | loss 0.07184 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time:  0.89s | valid loss 1.50630 | valid ppl     4.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |     4/   23 batches |lr 0.001073 | ms/batch 45.85 | loss 0.58310 | ppl     1.79\n",
            "| epoch  30 |     8/   23 batches |lr 0.001073 | ms/batch 34.34 | loss 0.07101 | ppl     1.07\n",
            "| epoch  30 |    12/   23 batches |lr 0.001073 | ms/batch 35.30 | loss 0.06091 | ppl     1.06\n",
            "| epoch  30 |    16/   23 batches |lr 0.001073 | ms/batch 34.27 | loss 0.03446 | ppl     1.04\n",
            "| epoch  30 |    20/   23 batches |lr 0.001073 | ms/batch 34.53 | loss 0.08674 | ppl     1.09\n",
            "tensor([0.4547, 0.4548, 0.4539, 0.4552, 0.4600, 0.4543, 0.4517, 0.4559, 0.4507,\n",
            "        0.4512, 0.4521, 0.4553, 0.4584, 0.4657, 0.4668, 0.4657, 0.4609, 0.4645,\n",
            "        0.4651, 0.4669, 0.4678, 0.4662, 0.4706, 0.4750, 0.4725, 0.4718, 0.4718,\n",
            "        0.4734, 0.4752, 0.4758, 0.4770, 0.4717, 0.4706, 0.4705, 0.4754, 0.4728,\n",
            "        0.4743, 0.4749, 0.4766, 0.4790, 0.4773, 0.4805, 0.4769, 0.4778, 0.4810,\n",
            "        0.4815, 0.4787, 0.4779, 0.4800, 0.4847, 0.4849, 0.4879, 0.4875, 0.4878,\n",
            "        0.4895, 0.4911, 0.4905, 0.4907, 0.4937, 0.4947, 0.4960, 0.4970, 0.4964,\n",
            "        0.4960, 0.5027, 0.5195, 0.5205, 0.5191, 0.5187, 0.5180, 0.5180, 0.5186,\n",
            "        0.5192, 0.5193, 0.5187, 0.5189, 0.5200, 0.5187, 0.5193, 0.5191, 0.5168,\n",
            "        0.5162, 0.5077, 0.4972, 0.4965, 0.4916, 0.4924, 0.4899, 0.4930, 0.4920,\n",
            "        0.4901, 0.4956, 0.4981, 0.4963, 0.4909, 0.4920, 0.4924, 0.4933, 0.4947,\n",
            "        0.4963, 0.4965, 0.4972, 0.4975, 0.4972, 0.4968, 0.4986, 0.4981, 0.4980,\n",
            "        0.4980, 0.4992, 0.4960, 0.4969, 0.4986, 0.4984, 0.5068, 0.5053, 0.5066,\n",
            "        0.5075, 0.5107, 0.5096, 0.5003, 0.4974, 0.4996, 0.4976, 0.4946, 0.5011,\n",
            "        0.5012, 0.5025, 0.5007, 0.4922, 0.4921, 0.4887, 0.4955, 0.4869, 0.4778,\n",
            "        0.4870, 0.4893, 0.4858, 0.4777, 0.4713, 0.4660, 0.4609, 0.4424, 0.4253,\n",
            "        0.4096, 0.4162, 0.4193, 0.4181, 0.4162, 0.3898, 0.3816, 0.3989, 0.3962,\n",
            "        0.4011, 0.3962, 0.3954, 0.3806, 0.3713, 0.3754, 0.3583, 0.3703, 0.3836,\n",
            "        0.3911, 0.4023, 0.4011, 0.4051, 0.4053, 0.3963, 0.4136, 0.4074])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time:  1.51s | valid loss 1.64454 | valid ppl     5.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |     4/   23 batches |lr 0.001020 | ms/batch 42.92 | loss 0.26378 | ppl     1.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  31 |     8/   23 batches |lr 0.001020 | ms/batch 36.09 | loss 0.04218 | ppl     1.04\n",
            "| epoch  31 |    12/   23 batches |lr 0.001020 | ms/batch 34.89 | loss 0.04243 | ppl     1.04\n",
            "| epoch  31 |    16/   23 batches |lr 0.001020 | ms/batch 34.35 | loss 0.01893 | ppl     1.02\n",
            "| epoch  31 |    20/   23 batches |lr 0.001020 | ms/batch 35.31 | loss 0.06281 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time:  0.88s | valid loss 1.57414 | valid ppl     4.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |     4/   23 batches |lr 0.000969 | ms/batch 45.04 | loss 0.16761 | ppl     1.18\n",
            "| epoch  32 |     8/   23 batches |lr 0.000969 | ms/batch 34.54 | loss 0.03809 | ppl     1.04\n",
            "| epoch  32 |    12/   23 batches |lr 0.000969 | ms/batch 34.86 | loss 0.02090 | ppl     1.02\n",
            "| epoch  32 |    16/   23 batches |lr 0.000969 | ms/batch 35.37 | loss 0.02298 | ppl     1.02\n",
            "| epoch  32 |    20/   23 batches |lr 0.000969 | ms/batch 34.90 | loss 0.07091 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time:  0.88s | valid loss 1.61925 | valid ppl     5.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |     4/   23 batches |lr 0.000920 | ms/batch 44.12 | loss 0.06486 | ppl     1.07\n",
            "| epoch  33 |     8/   23 batches |lr 0.000920 | ms/batch 34.47 | loss 0.05525 | ppl     1.06\n",
            "| epoch  33 |    12/   23 batches |lr 0.000920 | ms/batch 34.42 | loss 0.02219 | ppl     1.02\n",
            "| epoch  33 |    16/   23 batches |lr 0.000920 | ms/batch 35.50 | loss 0.02487 | ppl     1.03\n",
            "| epoch  33 |    20/   23 batches |lr 0.000920 | ms/batch 34.71 | loss 0.06494 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time:  0.87s | valid loss 1.51027 | valid ppl     4.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |     4/   23 batches |lr 0.000874 | ms/batch 43.82 | loss 0.20787 | ppl     1.23\n",
            "| epoch  34 |     8/   23 batches |lr 0.000874 | ms/batch 34.52 | loss 0.03868 | ppl     1.04\n",
            "| epoch  34 |    12/   23 batches |lr 0.000874 | ms/batch 34.45 | loss 0.01917 | ppl     1.02\n",
            "| epoch  34 |    16/   23 batches |lr 0.000874 | ms/batch 35.01 | loss 0.01911 | ppl     1.02\n",
            "| epoch  34 |    20/   23 batches |lr 0.000874 | ms/batch 36.99 | loss 0.06830 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time:  0.88s | valid loss 1.59852 | valid ppl     4.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |     4/   23 batches |lr 0.000830 | ms/batch 45.68 | loss 0.05201 | ppl     1.05\n",
            "| epoch  35 |     8/   23 batches |lr 0.000830 | ms/batch 34.60 | loss 0.11280 | ppl     1.12\n",
            "| epoch  35 |    12/   23 batches |lr 0.000830 | ms/batch 34.71 | loss 0.06113 | ppl     1.06\n",
            "| epoch  35 |    16/   23 batches |lr 0.000830 | ms/batch 34.64 | loss 0.03509 | ppl     1.04\n",
            "| epoch  35 |    20/   23 batches |lr 0.000830 | ms/batch 35.08 | loss 0.05669 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time:  0.88s | valid loss 1.58425 | valid ppl     4.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |     4/   23 batches |lr 0.000789 | ms/batch 45.53 | loss 0.18898 | ppl     1.21\n",
            "| epoch  36 |     8/   23 batches |lr 0.000789 | ms/batch 35.49 | loss 0.02876 | ppl     1.03\n",
            "| epoch  36 |    12/   23 batches |lr 0.000789 | ms/batch 35.32 | loss 0.01436 | ppl     1.01\n",
            "| epoch  36 |    16/   23 batches |lr 0.000789 | ms/batch 34.50 | loss 0.02040 | ppl     1.02\n",
            "| epoch  36 |    20/   23 batches |lr 0.000789 | ms/batch 35.07 | loss 0.07559 | ppl     1.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time:  0.88s | valid loss 1.56074 | valid ppl     4.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |     4/   23 batches |lr 0.000749 | ms/batch 45.31 | loss 0.05922 | ppl     1.06\n",
            "| epoch  37 |     8/   23 batches |lr 0.000749 | ms/batch 35.84 | loss 0.06010 | ppl     1.06\n",
            "| epoch  37 |    12/   23 batches |lr 0.000749 | ms/batch 34.78 | loss 0.02391 | ppl     1.02\n",
            "| epoch  37 |    16/   23 batches |lr 0.000749 | ms/batch 35.06 | loss 0.02221 | ppl     1.02\n",
            "| epoch  37 |    20/   23 batches |lr 0.000749 | ms/batch 34.59 | loss 0.05549 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time:  0.88s | valid loss 1.59191 | valid ppl     4.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |     4/   23 batches |lr 0.000712 | ms/batch 45.30 | loss 0.14115 | ppl     1.15\n",
            "| epoch  38 |     8/   23 batches |lr 0.000712 | ms/batch 35.39 | loss 0.02884 | ppl     1.03\n",
            "| epoch  38 |    12/   23 batches |lr 0.000712 | ms/batch 34.34 | loss 0.01194 | ppl     1.01\n",
            "| epoch  38 |    16/   23 batches |lr 0.000712 | ms/batch 34.84 | loss 0.01655 | ppl     1.02\n",
            "| epoch  38 |    20/   23 batches |lr 0.000712 | ms/batch 34.73 | loss 0.06626 | ppl     1.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time:  0.88s | valid loss 1.52688 | valid ppl     4.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |     4/   23 batches |lr 0.000676 | ms/batch 44.26 | loss 0.05941 | ppl     1.06\n",
            "| epoch  39 |     8/   23 batches |lr 0.000676 | ms/batch 35.03 | loss 0.04560 | ppl     1.05\n",
            "| epoch  39 |    12/   23 batches |lr 0.000676 | ms/batch 35.98 | loss 0.01375 | ppl     1.01\n",
            "| epoch  39 |    16/   23 batches |lr 0.000676 | ms/batch 34.45 | loss 0.01932 | ppl     1.02\n",
            "| epoch  39 |    20/   23 batches |lr 0.000676 | ms/batch 34.66 | loss 0.05145 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time:  0.88s | valid loss 1.55980 | valid ppl     4.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |     4/   23 batches |lr 0.000643 | ms/batch 45.44 | loss 0.12393 | ppl     1.13\n",
            "| epoch  40 |     8/   23 batches |lr 0.000643 | ms/batch 34.73 | loss 0.02172 | ppl     1.02\n",
            "| epoch  40 |    12/   23 batches |lr 0.000643 | ms/batch 34.83 | loss 0.01051 | ppl     1.01\n",
            "| epoch  40 |    16/   23 batches |lr 0.000643 | ms/batch 36.47 | loss 0.01453 | ppl     1.01\n",
            "| epoch  40 |    20/   23 batches |lr 0.000643 | ms/batch 37.47 | loss 0.05958 | ppl     1.06\n",
            "tensor([0.4649, 0.4619, 0.4628, 0.4636, 0.4700, 0.4631, 0.4584, 0.4637, 0.4585,\n",
            "        0.4566, 0.4573, 0.4648, 0.4722, 0.4849, 0.4880, 0.4844, 0.4795, 0.4851,\n",
            "        0.4859, 0.4896, 0.4921, 0.4886, 0.4962, 0.5032, 0.5007, 0.5004, 0.5020,\n",
            "        0.5053, 0.5090, 0.5116, 0.5150, 0.5115, 0.5074, 0.5103, 0.5173, 0.5144,\n",
            "        0.5163, 0.5198, 0.5257, 0.5273, 0.5266, 0.5302, 0.5254, 0.5273, 0.5340,\n",
            "        0.5350, 0.5307, 0.5308, 0.5339, 0.5436, 0.5438, 0.5488, 0.5483, 0.5498,\n",
            "        0.5532, 0.5534, 0.5544, 0.5580, 0.5777, 0.5663, 0.5695, 0.5711, 0.5706,\n",
            "        0.5707, 0.5832, 0.6345, 0.6365, 0.6341, 0.6334, 0.6331, 0.6322, 0.6322,\n",
            "        0.6342, 0.6364, 0.6376, 0.6386, 0.6423, 0.6407, 0.6415, 0.6399, 0.6332,\n",
            "        0.6333, 0.5803, 0.5791, 0.5779, 0.5707, 0.5725, 0.5703, 0.5747, 0.5712,\n",
            "        0.5658, 0.5645, 0.5868, 0.5851, 0.5798, 0.5355, 0.5454, 0.5447, 0.5375,\n",
            "        0.5372, 0.5374, 0.5380, 0.5380, 0.5370, 0.5366, 0.5392, 0.5379, 0.5378,\n",
            "        0.5373, 0.5397, 0.5358, 0.5373, 0.5397, 0.5390, 0.5591, 0.5611, 0.5651,\n",
            "        0.5630, 0.5726, 0.5615, 0.5483, 0.5401, 0.5452, 0.5492, 0.5479, 0.5455,\n",
            "        0.5435, 0.5454, 0.5355, 0.5258, 0.5236, 0.5355, 0.5379, 0.5239, 0.5269,\n",
            "        0.5407, 0.5396, 0.5266, 0.5131, 0.5122, 0.5026, 0.4859, 0.4597, 0.4359,\n",
            "        0.4057, 0.4171, 0.4236, 0.4204, 0.4169, 0.3979, 0.3906, 0.4159, 0.4118,\n",
            "        0.4148, 0.4086, 0.4070, 0.3880, 0.3738, 0.3807, 0.3697, 0.3884, 0.3998,\n",
            "        0.4225, 0.4410, 0.4376, 0.4440, 0.4414, 0.4340, 0.4511, 0.4440])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time:  1.63s | valid loss 1.53001 | valid ppl     4.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  41 |     4/   23 batches |lr 0.000610 | ms/batch 45.90 | loss 0.05273 | ppl     1.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  41 |     8/   23 batches |lr 0.000610 | ms/batch 38.26 | loss 0.03712 | ppl     1.04\n",
            "| epoch  41 |    12/   23 batches |lr 0.000610 | ms/batch 36.43 | loss 0.01136 | ppl     1.01\n",
            "| epoch  41 |    16/   23 batches |lr 0.000610 | ms/batch 36.26 | loss 0.01882 | ppl     1.02\n",
            "| epoch  41 |    20/   23 batches |lr 0.000610 | ms/batch 34.85 | loss 0.04815 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time:  0.91s | valid loss 1.55337 | valid ppl     4.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |     4/   23 batches |lr 0.000580 | ms/batch 44.26 | loss 0.11773 | ppl     1.12\n",
            "| epoch  42 |     8/   23 batches |lr 0.000580 | ms/batch 34.31 | loss 0.02004 | ppl     1.02\n",
            "| epoch  42 |    12/   23 batches |lr 0.000580 | ms/batch 34.29 | loss 0.00978 | ppl     1.01\n",
            "| epoch  42 |    16/   23 batches |lr 0.000580 | ms/batch 34.46 | loss 0.01385 | ppl     1.01\n",
            "| epoch  42 |    20/   23 batches |lr 0.000580 | ms/batch 34.75 | loss 0.05347 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time:  0.87s | valid loss 1.49709 | valid ppl     4.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |     4/   23 batches |lr 0.000551 | ms/batch 44.12 | loss 0.04995 | ppl     1.05\n",
            "| epoch  43 |     8/   23 batches |lr 0.000551 | ms/batch 35.45 | loss 0.03468 | ppl     1.04\n",
            "| epoch  43 |    12/   23 batches |lr 0.000551 | ms/batch 34.12 | loss 0.00938 | ppl     1.01\n",
            "| epoch  43 |    16/   23 batches |lr 0.000551 | ms/batch 34.70 | loss 0.01750 | ppl     1.02\n",
            "| epoch  43 |    20/   23 batches |lr 0.000551 | ms/batch 34.53 | loss 0.04350 | ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time:  0.87s | valid loss 1.51993 | valid ppl     4.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |     4/   23 batches |lr 0.000523 | ms/batch 45.60 | loss 0.10562 | ppl     1.11\n",
            "| epoch  44 |     8/   23 batches |lr 0.000523 | ms/batch 34.59 | loss 0.01961 | ppl     1.02\n",
            "| epoch  44 |    12/   23 batches |lr 0.000523 | ms/batch 34.57 | loss 0.01034 | ppl     1.01\n",
            "| epoch  44 |    16/   23 batches |lr 0.000523 | ms/batch 34.68 | loss 0.01311 | ppl     1.01\n",
            "| epoch  44 |    20/   23 batches |lr 0.000523 | ms/batch 35.15 | loss 0.05302 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time:  0.88s | valid loss 1.49878 | valid ppl     4.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |     4/   23 batches |lr 0.000497 | ms/batch 44.64 | loss 0.04503 | ppl     1.05\n",
            "| epoch  45 |     8/   23 batches |lr 0.000497 | ms/batch 34.31 | loss 0.02935 | ppl     1.03\n",
            "| epoch  45 |    12/   23 batches |lr 0.000497 | ms/batch 34.25 | loss 0.01009 | ppl     1.01\n",
            "| epoch  45 |    16/   23 batches |lr 0.000497 | ms/batch 34.50 | loss 0.01829 | ppl     1.02\n",
            "| epoch  45 |    20/   23 batches |lr 0.000497 | ms/batch 34.71 | loss 0.03978 | ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time:  0.87s | valid loss 1.53140 | valid ppl     4.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |     4/   23 batches |lr 0.000472 | ms/batch 44.61 | loss 0.08494 | ppl     1.09\n",
            "| epoch  46 |     8/   23 batches |lr 0.000472 | ms/batch 35.02 | loss 0.01712 | ppl     1.02\n",
            "| epoch  46 |    12/   23 batches |lr 0.000472 | ms/batch 37.45 | loss 0.00928 | ppl     1.01\n",
            "| epoch  46 |    16/   23 batches |lr 0.000472 | ms/batch 36.54 | loss 0.01230 | ppl     1.01\n",
            "| epoch  46 |    20/   23 batches |lr 0.000472 | ms/batch 38.28 | loss 0.04673 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time:  0.91s | valid loss 1.48090 | valid ppl     4.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |     4/   23 batches |lr 0.000449 | ms/batch 48.21 | loss 0.04794 | ppl     1.05\n",
            "| epoch  47 |     8/   23 batches |lr 0.000449 | ms/batch 37.51 | loss 0.02816 | ppl     1.03\n",
            "| epoch  47 |    12/   23 batches |lr 0.000449 | ms/batch 36.46 | loss 0.00813 | ppl     1.01\n",
            "| epoch  47 |    16/   23 batches |lr 0.000449 | ms/batch 36.53 | loss 0.01742 | ppl     1.02\n",
            "| epoch  47 |    20/   23 batches |lr 0.000449 | ms/batch 37.81 | loss 0.03553 | ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time:  0.93s | valid loss 1.52715 | valid ppl     4.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |     4/   23 batches |lr 0.000426 | ms/batch 46.25 | loss 0.08253 | ppl     1.09\n",
            "| epoch  48 |     8/   23 batches |lr 0.000426 | ms/batch 36.02 | loss 0.01733 | ppl     1.02\n",
            "| epoch  48 |    12/   23 batches |lr 0.000426 | ms/batch 36.34 | loss 0.00843 | ppl     1.01\n",
            "| epoch  48 |    16/   23 batches |lr 0.000426 | ms/batch 36.15 | loss 0.01229 | ppl     1.01\n",
            "| epoch  48 |    20/   23 batches |lr 0.000426 | ms/batch 34.85 | loss 0.04119 | ppl     1.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time:  0.90s | valid loss 1.46848 | valid ppl     4.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |     4/   23 batches |lr 0.000405 | ms/batch 44.99 | loss 0.04290 | ppl     1.04\n",
            "| epoch  49 |     8/   23 batches |lr 0.000405 | ms/batch 35.01 | loss 0.02522 | ppl     1.03\n",
            "| epoch  49 |    12/   23 batches |lr 0.000405 | ms/batch 34.72 | loss 0.00880 | ppl     1.01\n",
            "| epoch  49 |    16/   23 batches |lr 0.000405 | ms/batch 35.07 | loss 0.01600 | ppl     1.02\n",
            "| epoch  49 |    20/   23 batches |lr 0.000405 | ms/batch 35.46 | loss 0.03272 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time:  0.88s | valid loss 1.50937 | valid ppl     4.52\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |     4/   23 batches |lr 0.000385 | ms/batch 44.75 | loss 0.07431 | ppl     1.08\n",
            "| epoch  50 |     8/   23 batches |lr 0.000385 | ms/batch 35.10 | loss 0.01652 | ppl     1.02\n",
            "| epoch  50 |    12/   23 batches |lr 0.000385 | ms/batch 34.59 | loss 0.00869 | ppl     1.01\n",
            "| epoch  50 |    16/   23 batches |lr 0.000385 | ms/batch 35.10 | loss 0.01097 | ppl     1.01\n",
            "| epoch  50 |    20/   23 batches |lr 0.000385 | ms/batch 34.94 | loss 0.03808 | ppl     1.04\n",
            "tensor([0.4065, 0.4035, 0.4049, 0.4056, 0.4136, 0.4048, 0.3999, 0.4087, 0.4000,\n",
            "        0.3994, 0.4001, 0.4085, 0.4174, 0.4373, 0.4428, 0.4384, 0.4338, 0.4432,\n",
            "        0.4478, 0.4532, 0.4565, 0.4536, 0.4625, 0.4720, 0.4706, 0.4720, 0.4770,\n",
            "        0.4813, 0.4853, 0.4871, 0.4918, 0.4923, 0.4882, 0.4909, 0.5003, 0.4976,\n",
            "        0.4996, 0.5048, 0.5123, 0.5170, 0.5158, 0.5215, 0.5155, 0.5175, 0.5253,\n",
            "        0.5275, 0.5249, 0.5264, 0.5299, 0.5384, 0.5410, 0.5473, 0.5474, 0.5472,\n",
            "        0.5522, 0.5531, 0.5632, 0.6030, 0.6273, 0.5997, 0.5772, 0.5787, 0.5961,\n",
            "        0.5779, 0.6455, 0.6475, 0.6517, 0.6732, 0.6720, 0.6712, 0.6708, 0.6716,\n",
            "        0.6766, 0.6780, 0.6797, 0.6809, 0.6850, 0.6840, 0.6864, 0.6858, 0.6792,\n",
            "        0.6728, 0.6070, 0.6063, 0.6034, 0.5991, 0.5900, 0.5872, 0.6002, 0.5966,\n",
            "        0.5842, 0.5656, 0.5554, 0.5524, 0.5537, 0.5559, 0.5561, 0.5570, 0.5595,\n",
            "        0.5614, 0.5613, 0.5612, 0.5602, 0.5582, 0.5567, 0.5588, 0.5571, 0.5562,\n",
            "        0.5556, 0.5578, 0.5539, 0.5554, 0.5583, 0.5592, 0.5942, 0.5946, 0.5975,\n",
            "        0.5983, 0.6067, 0.6034, 0.5870, 0.5625, 0.5647, 0.5651, 0.5655, 0.5599,\n",
            "        0.5542, 0.5555, 0.5473, 0.5296, 0.5279, 0.5694, 0.5579, 0.5422, 0.5632,\n",
            "        0.5790, 0.5760, 0.5589, 0.5439, 0.5489, 0.5403, 0.5031, 0.4794, 0.4535,\n",
            "        0.4226, 0.4342, 0.4361, 0.4279, 0.4248, 0.4379, 0.4287, 0.4551, 0.4550,\n",
            "        0.4614, 0.4545, 0.4539, 0.4324, 0.4180, 0.4291, 0.4146, 0.4340, 0.4498,\n",
            "        0.4682, 0.4876, 0.4791, 0.4890, 0.4858, 0.4815, 0.4994, 0.4926])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time:  1.53s | valid loss 1.48509 | valid ppl     4.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  51 |     4/   23 batches |lr 0.000365 | ms/batch 42.94 | loss 0.03884 | ppl     1.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  51 |     8/   23 batches |lr 0.000365 | ms/batch 35.64 | loss 0.02377 | ppl     1.02\n",
            "| epoch  51 |    12/   23 batches |lr 0.000365 | ms/batch 34.45 | loss 0.00896 | ppl     1.01\n",
            "| epoch  51 |    16/   23 batches |lr 0.000365 | ms/batch 34.69 | loss 0.01586 | ppl     1.02\n",
            "| epoch  51 |    20/   23 batches |lr 0.000365 | ms/batch 34.98 | loss 0.02985 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time:  0.87s | valid loss 1.49294 | valid ppl     4.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |     4/   23 batches |lr 0.000347 | ms/batch 44.93 | loss 0.06717 | ppl     1.07\n",
            "| epoch  52 |     8/   23 batches |lr 0.000347 | ms/batch 34.69 | loss 0.01528 | ppl     1.02\n",
            "| epoch  52 |    12/   23 batches |lr 0.000347 | ms/batch 36.66 | loss 0.00892 | ppl     1.01\n",
            "| epoch  52 |    16/   23 batches |lr 0.000347 | ms/batch 36.69 | loss 0.01179 | ppl     1.01\n",
            "| epoch  52 |    20/   23 batches |lr 0.000347 | ms/batch 36.53 | loss 0.03165 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time:  0.91s | valid loss 1.46087 | valid ppl     4.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |     4/   23 batches |lr 0.000330 | ms/batch 47.03 | loss 0.04703 | ppl     1.05\n",
            "| epoch  53 |     8/   23 batches |lr 0.000330 | ms/batch 36.97 | loss 0.02077 | ppl     1.02\n",
            "| epoch  53 |    12/   23 batches |lr 0.000330 | ms/batch 35.49 | loss 0.00808 | ppl     1.01\n",
            "| epoch  53 |    16/   23 batches |lr 0.000330 | ms/batch 34.82 | loss 0.01528 | ppl     1.02\n",
            "| epoch  53 |    20/   23 batches |lr 0.000330 | ms/batch 34.72 | loss 0.02726 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time:  0.90s | valid loss 1.50407 | valid ppl     4.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |     4/   23 batches |lr 0.000313 | ms/batch 43.96 | loss 0.06190 | ppl     1.06\n",
            "| epoch  54 |     8/   23 batches |lr 0.000313 | ms/batch 34.65 | loss 0.01666 | ppl     1.02\n",
            "| epoch  54 |    12/   23 batches |lr 0.000313 | ms/batch 34.84 | loss 0.00736 | ppl     1.01\n",
            "| epoch  54 |    16/   23 batches |lr 0.000313 | ms/batch 36.41 | loss 0.01137 | ppl     1.01\n",
            "| epoch  54 |    20/   23 batches |lr 0.000313 | ms/batch 34.82 | loss 0.03148 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time:  0.87s | valid loss 1.46997 | valid ppl     4.35\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |     4/   23 batches |lr 0.000298 | ms/batch 44.43 | loss 0.04391 | ppl     1.04\n",
            "| epoch  55 |     8/   23 batches |lr 0.000298 | ms/batch 34.34 | loss 0.02052 | ppl     1.02\n",
            "| epoch  55 |    12/   23 batches |lr 0.000298 | ms/batch 34.75 | loss 0.00706 | ppl     1.01\n",
            "| epoch  55 |    16/   23 batches |lr 0.000298 | ms/batch 36.33 | loss 0.01470 | ppl     1.01\n",
            "| epoch  55 |    20/   23 batches |lr 0.000298 | ms/batch 35.22 | loss 0.02598 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time:  0.88s | valid loss 1.50629 | valid ppl     4.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |     4/   23 batches |lr 0.000283 | ms/batch 44.61 | loss 0.05062 | ppl     1.05\n",
            "| epoch  56 |     8/   23 batches |lr 0.000283 | ms/batch 34.91 | loss 0.01597 | ppl     1.02\n",
            "| epoch  56 |    12/   23 batches |lr 0.000283 | ms/batch 34.94 | loss 0.00733 | ppl     1.01\n",
            "| epoch  56 |    16/   23 batches |lr 0.000283 | ms/batch 34.51 | loss 0.01117 | ppl     1.01\n",
            "| epoch  56 |    20/   23 batches |lr 0.000283 | ms/batch 34.41 | loss 0.02706 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time:  0.87s | valid loss 1.46635 | valid ppl     4.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |     4/   23 batches |lr 0.000269 | ms/batch 44.52 | loss 0.04842 | ppl     1.05\n",
            "| epoch  57 |     8/   23 batches |lr 0.000269 | ms/batch 34.52 | loss 0.01858 | ppl     1.02\n",
            "| epoch  57 |    12/   23 batches |lr 0.000269 | ms/batch 34.75 | loss 0.00723 | ppl     1.01\n",
            "| epoch  57 |    16/   23 batches |lr 0.000269 | ms/batch 34.24 | loss 0.01267 | ppl     1.01\n",
            "| epoch  57 |    20/   23 batches |lr 0.000269 | ms/batch 34.51 | loss 0.02475 | ppl     1.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time:  0.87s | valid loss 1.47805 | valid ppl     4.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |     4/   23 batches |lr 0.000255 | ms/batch 44.65 | loss 0.04932 | ppl     1.05\n",
            "| epoch  58 |     8/   23 batches |lr 0.000255 | ms/batch 34.88 | loss 0.01538 | ppl     1.02\n",
            "| epoch  58 |    12/   23 batches |lr 0.000255 | ms/batch 34.89 | loss 0.00733 | ppl     1.01\n",
            "| epoch  58 |    16/   23 batches |lr 0.000255 | ms/batch 35.10 | loss 0.01061 | ppl     1.01\n",
            "| epoch  58 |    20/   23 batches |lr 0.000255 | ms/batch 34.71 | loss 0.02444 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time:  0.88s | valid loss 1.44999 | valid ppl     4.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |     4/   23 batches |lr 0.000242 | ms/batch 44.38 | loss 0.04236 | ppl     1.04\n",
            "| epoch  59 |     8/   23 batches |lr 0.000242 | ms/batch 34.74 | loss 0.01994 | ppl     1.02\n",
            "| epoch  59 |    12/   23 batches |lr 0.000242 | ms/batch 35.45 | loss 0.00751 | ppl     1.01\n",
            "| epoch  59 |    16/   23 batches |lr 0.000242 | ms/batch 36.29 | loss 0.01246 | ppl     1.01\n",
            "| epoch  59 |    20/   23 batches |lr 0.000242 | ms/batch 37.50 | loss 0.02242 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time:  0.90s | valid loss 1.47197 | valid ppl     4.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |     4/   23 batches |lr 0.000230 | ms/batch 46.53 | loss 0.04267 | ppl     1.04\n",
            "| epoch  60 |     8/   23 batches |lr 0.000230 | ms/batch 34.75 | loss 0.01632 | ppl     1.02\n",
            "| epoch  60 |    12/   23 batches |lr 0.000230 | ms/batch 34.34 | loss 0.00748 | ppl     1.01\n",
            "| epoch  60 |    16/   23 batches |lr 0.000230 | ms/batch 34.70 | loss 0.01138 | ppl     1.01\n",
            "| epoch  60 |    20/   23 batches |lr 0.000230 | ms/batch 34.49 | loss 0.02239 | ppl     1.02\n",
            "tensor([0.3339, 0.3262, 0.3264, 0.3267, 0.3381, 0.3360, 0.3328, 0.3417, 0.3347,\n",
            "        0.3320, 0.3313, 0.3408, 0.3498, 0.3784, 0.3856, 0.3782, 0.3767, 0.3904,\n",
            "        0.3967, 0.4035, 0.4085, 0.4066, 0.4166, 0.4268, 0.4271, 0.4322, 0.4392,\n",
            "        0.4445, 0.4481, 0.4500, 0.4569, 0.4600, 0.4557, 0.4618, 0.4703, 0.4673,\n",
            "        0.4699, 0.4770, 0.4867, 0.4918, 0.4925, 0.4976, 0.4915, 0.4932, 0.5015,\n",
            "        0.5043, 0.5033, 0.5066, 0.5104, 0.5182, 0.5212, 0.5277, 0.5277, 0.5273,\n",
            "        0.5326, 0.5341, 0.5697, 0.6040, 0.6223, 0.6102, 0.5627, 0.5628, 0.6164,\n",
            "        0.5676, 0.6429, 0.6441, 0.6487, 0.6792, 0.6769, 0.6769, 0.6764, 0.6765,\n",
            "        0.6819, 0.6844, 0.6865, 0.6880, 0.6923, 0.6956, 0.6969, 0.6964, 0.6916,\n",
            "        0.6896, 0.6134, 0.6136, 0.6143, 0.6091, 0.6050, 0.6040, 0.6119, 0.6053,\n",
            "        0.5900, 0.5722, 0.5661, 0.5743, 0.5623, 0.5621, 0.5634, 0.5629, 0.5646,\n",
            "        0.5657, 0.5650, 0.5640, 0.5620, 0.5590, 0.5571, 0.5579, 0.5556, 0.5542,\n",
            "        0.5532, 0.5553, 0.5524, 0.5543, 0.5566, 0.5603, 0.6077, 0.6048, 0.6083,\n",
            "        0.6077, 0.6156, 0.6124, 0.5942, 0.5654, 0.5602, 0.5616, 0.5621, 0.5532,\n",
            "        0.5437, 0.5426, 0.5283, 0.5121, 0.5123, 0.5714, 0.5588, 0.5450, 0.5879,\n",
            "        0.6005, 0.5937, 0.5720, 0.5599, 0.5729, 0.5612, 0.5036, 0.4928, 0.4645,\n",
            "        0.4374, 0.4512, 0.4447, 0.4394, 0.4341, 0.4803, 0.4735, 0.4998, 0.5005,\n",
            "        0.5042, 0.4993, 0.4987, 0.4802, 0.4644, 0.4791, 0.4702, 0.4843, 0.4977,\n",
            "        0.5134, 0.5277, 0.5214, 0.5299, 0.5269, 0.5254, 0.5426, 0.5383])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time:  1.53s | valid loss 1.46862 | valid ppl     4.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  61 |     4/   23 batches |lr 0.000219 | ms/batch 43.04 | loss 0.04595 | ppl     1.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  61 |     8/   23 batches |lr 0.000219 | ms/batch 35.17 | loss 0.01553 | ppl     1.02\n",
            "| epoch  61 |    12/   23 batches |lr 0.000219 | ms/batch 34.39 | loss 0.00751 | ppl     1.01\n",
            "| epoch  61 |    16/   23 batches |lr 0.000219 | ms/batch 34.51 | loss 0.01204 | ppl     1.01\n",
            "| epoch  61 |    20/   23 batches |lr 0.000219 | ms/batch 34.60 | loss 0.01981 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time:  0.86s | valid loss 1.46790 | valid ppl     4.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |     4/   23 batches |lr 0.000208 | ms/batch 45.85 | loss 0.04915 | ppl     1.05\n",
            "| epoch  62 |     8/   23 batches |lr 0.000208 | ms/batch 34.14 | loss 0.01397 | ppl     1.01\n",
            "| epoch  62 |    12/   23 batches |lr 0.000208 | ms/batch 35.01 | loss 0.00673 | ppl     1.01\n",
            "| epoch  62 |    16/   23 batches |lr 0.000208 | ms/batch 34.47 | loss 0.01105 | ppl     1.01\n",
            "| epoch  62 |    20/   23 batches |lr 0.000208 | ms/batch 34.99 | loss 0.02084 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time:  0.88s | valid loss 1.45061 | valid ppl     4.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |     4/   23 batches |lr 0.000197 | ms/batch 43.73 | loss 0.04325 | ppl     1.04\n",
            "| epoch  63 |     8/   23 batches |lr 0.000197 | ms/batch 34.31 | loss 0.01595 | ppl     1.02\n",
            "| epoch  63 |    12/   23 batches |lr 0.000197 | ms/batch 34.30 | loss 0.00624 | ppl     1.01\n",
            "| epoch  63 |    16/   23 batches |lr 0.000197 | ms/batch 35.12 | loss 0.01138 | ppl     1.01\n",
            "| epoch  63 |    20/   23 batches |lr 0.000197 | ms/batch 34.37 | loss 0.02007 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time:  0.86s | valid loss 1.45839 | valid ppl     4.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |     4/   23 batches |lr 0.000188 | ms/batch 44.49 | loss 0.03967 | ppl     1.04\n",
            "| epoch  64 |     8/   23 batches |lr 0.000188 | ms/batch 34.51 | loss 0.01625 | ppl     1.02\n",
            "| epoch  64 |    12/   23 batches |lr 0.000188 | ms/batch 34.05 | loss 0.00749 | ppl     1.01\n",
            "| epoch  64 |    16/   23 batches |lr 0.000188 | ms/batch 34.30 | loss 0.01137 | ppl     1.01\n",
            "| epoch  64 |    20/   23 batches |lr 0.000188 | ms/batch 34.45 | loss 0.01967 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time:  0.86s | valid loss 1.45313 | valid ppl     4.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |     4/   23 batches |lr 0.000178 | ms/batch 44.38 | loss 0.04516 | ppl     1.05\n",
            "| epoch  65 |     8/   23 batches |lr 0.000178 | ms/batch 34.28 | loss 0.01540 | ppl     1.02\n",
            "| epoch  65 |    12/   23 batches |lr 0.000178 | ms/batch 34.43 | loss 0.00666 | ppl     1.01\n",
            "| epoch  65 |    16/   23 batches |lr 0.000178 | ms/batch 34.41 | loss 0.01126 | ppl     1.01\n",
            "| epoch  65 |    20/   23 batches |lr 0.000178 | ms/batch 34.55 | loss 0.01812 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time:  0.87s | valid loss 1.45239 | valid ppl     4.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |     4/   23 batches |lr 0.000169 | ms/batch 43.49 | loss 0.04102 | ppl     1.04\n",
            "| epoch  66 |     8/   23 batches |lr 0.000169 | ms/batch 34.51 | loss 0.01564 | ppl     1.02\n",
            "| epoch  66 |    12/   23 batches |lr 0.000169 | ms/batch 34.68 | loss 0.00663 | ppl     1.01\n",
            "| epoch  66 |    16/   23 batches |lr 0.000169 | ms/batch 35.83 | loss 0.01090 | ppl     1.01\n",
            "| epoch  66 |    20/   23 batches |lr 0.000169 | ms/batch 36.29 | loss 0.01848 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time:  0.88s | valid loss 1.45533 | valid ppl     4.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |     4/   23 batches |lr 0.000161 | ms/batch 49.15 | loss 0.04148 | ppl     1.04\n",
            "| epoch  67 |     8/   23 batches |lr 0.000161 | ms/batch 35.90 | loss 0.01529 | ppl     1.02\n",
            "| epoch  67 |    12/   23 batches |lr 0.000161 | ms/batch 34.11 | loss 0.00661 | ppl     1.01\n",
            "| epoch  67 |    16/   23 batches |lr 0.000161 | ms/batch 35.39 | loss 0.01092 | ppl     1.01\n",
            "| epoch  67 |    20/   23 batches |lr 0.000161 | ms/batch 34.21 | loss 0.01737 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time:  0.89s | valid loss 1.44852 | valid ppl     4.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |     4/   23 batches |lr 0.000153 | ms/batch 43.90 | loss 0.04556 | ppl     1.05\n",
            "| epoch  68 |     8/   23 batches |lr 0.000153 | ms/batch 34.48 | loss 0.01371 | ppl     1.01\n",
            "| epoch  68 |    12/   23 batches |lr 0.000153 | ms/batch 34.46 | loss 0.00637 | ppl     1.01\n",
            "| epoch  68 |    16/   23 batches |lr 0.000153 | ms/batch 34.47 | loss 0.01061 | ppl     1.01\n",
            "| epoch  68 |    20/   23 batches |lr 0.000153 | ms/batch 34.03 | loss 0.01781 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time:  0.86s | valid loss 1.44476 | valid ppl     4.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |     4/   23 batches |lr 0.000145 | ms/batch 44.85 | loss 0.04095 | ppl     1.04\n",
            "| epoch  69 |     8/   23 batches |lr 0.000145 | ms/batch 34.20 | loss 0.01399 | ppl     1.01\n",
            "| epoch  69 |    12/   23 batches |lr 0.000145 | ms/batch 34.82 | loss 0.00655 | ppl     1.01\n",
            "| epoch  69 |    16/   23 batches |lr 0.000145 | ms/batch 35.83 | loss 0.01065 | ppl     1.01\n",
            "| epoch  69 |    20/   23 batches |lr 0.000145 | ms/batch 36.19 | loss 0.01652 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time:  0.88s | valid loss 1.43931 | valid ppl     4.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |     4/   23 batches |lr 0.000138 | ms/batch 43.64 | loss 0.04002 | ppl     1.04\n",
            "| epoch  70 |     8/   23 batches |lr 0.000138 | ms/batch 34.28 | loss 0.01534 | ppl     1.02\n",
            "| epoch  70 |    12/   23 batches |lr 0.000138 | ms/batch 33.85 | loss 0.00653 | ppl     1.01\n",
            "| epoch  70 |    16/   23 batches |lr 0.000138 | ms/batch 35.01 | loss 0.01107 | ppl     1.01\n",
            "| epoch  70 |    20/   23 batches |lr 0.000138 | ms/batch 34.23 | loss 0.01607 | ppl     1.02\n",
            "tensor([0.3005, 0.2976, 0.2967, 0.2957, 0.3018, 0.2940, 0.2940, 0.3068, 0.3037,\n",
            "        0.3022, 0.3012, 0.3065, 0.3104, 0.3312, 0.3430, 0.3415, 0.3396, 0.3547,\n",
            "        0.3627, 0.3706, 0.3746, 0.3756, 0.3860, 0.3952, 0.3992, 0.4063, 0.4158,\n",
            "        0.4213, 0.4244, 0.4260, 0.4334, 0.4402, 0.4363, 0.4432, 0.4514, 0.4489,\n",
            "        0.4513, 0.4583, 0.4700, 0.4766, 0.4775, 0.4829, 0.4769, 0.4781, 0.4859,\n",
            "        0.4895, 0.4902, 0.4941, 0.4992, 0.5058, 0.5083, 0.5146, 0.5140, 0.5133,\n",
            "        0.5190, 0.5414, 0.5944, 0.5990, 0.6143, 0.6145, 0.6119, 0.5997, 0.6257,\n",
            "        0.6290, 0.6353, 0.6362, 0.6416, 0.6474, 0.6735, 0.6738, 0.6736, 0.6734,\n",
            "        0.6738, 0.6791, 0.6818, 0.6825, 0.6868, 0.6937, 0.6970, 0.6962, 0.6922,\n",
            "        0.6901, 0.6172, 0.6178, 0.6189, 0.6140, 0.6089, 0.6108, 0.6140, 0.6061,\n",
            "        0.5900, 0.5749, 0.5851, 0.5950, 0.5775, 0.5687, 0.5794, 0.5759, 0.5689,\n",
            "        0.5685, 0.5674, 0.5656, 0.5629, 0.5594, 0.5569, 0.5570, 0.5544, 0.5679,\n",
            "        0.5674, 0.5535, 0.5522, 0.5534, 0.5553, 0.5584, 0.6163, 0.6112, 0.6136,\n",
            "        0.6114, 0.6191, 0.6159, 0.5920, 0.5693, 0.5585, 0.5580, 0.5581, 0.5483,\n",
            "        0.5360, 0.5348, 0.5302, 0.4747, 0.4792, 0.5704, 0.5595, 0.5477, 0.6044,\n",
            "        0.6145, 0.6044, 0.5782, 0.5712, 0.5910, 0.5813, 0.5170, 0.5008, 0.4746,\n",
            "        0.4480, 0.4702, 0.4563, 0.4543, 0.4482, 0.5171, 0.5092, 0.5350, 0.5369,\n",
            "        0.5403, 0.5363, 0.5360, 0.5214, 0.5037, 0.5212, 0.5142, 0.5243, 0.5373,\n",
            "        0.5491, 0.5602, 0.5551, 0.5630, 0.5599, 0.5595, 0.5775, 0.5753])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time:  1.51s | valid loss 1.45498 | valid ppl     4.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  71 |     4/   23 batches |lr 0.000131 | ms/batch 42.39 | loss 0.04087 | ppl     1.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  71 |     8/   23 batches |lr 0.000131 | ms/batch 34.85 | loss 0.01386 | ppl     1.01\n",
            "| epoch  71 |    12/   23 batches |lr 0.000131 | ms/batch 34.54 | loss 0.00663 | ppl     1.01\n",
            "| epoch  71 |    16/   23 batches |lr 0.000131 | ms/batch 34.20 | loss 0.01117 | ppl     1.01\n",
            "| epoch  71 |    20/   23 batches |lr 0.000131 | ms/batch 34.13 | loss 0.01695 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time:  0.86s | valid loss 1.43718 | valid ppl     4.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |     4/   23 batches |lr 0.000124 | ms/batch 44.43 | loss 0.04272 | ppl     1.04\n",
            "| epoch  72 |     8/   23 batches |lr 0.000124 | ms/batch 33.97 | loss 0.01333 | ppl     1.01\n",
            "| epoch  72 |    12/   23 batches |lr 0.000124 | ms/batch 34.21 | loss 0.00689 | ppl     1.01\n",
            "| epoch  72 |    16/   23 batches |lr 0.000124 | ms/batch 34.57 | loss 0.01020 | ppl     1.01\n",
            "| epoch  72 |    20/   23 batches |lr 0.000124 | ms/batch 34.17 | loss 0.01580 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time:  0.86s | valid loss 1.43401 | valid ppl     4.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |     4/   23 batches |lr 0.000118 | ms/batch 44.70 | loss 0.04355 | ppl     1.04\n",
            "| epoch  73 |     8/   23 batches |lr 0.000118 | ms/batch 34.98 | loss 0.01356 | ppl     1.01\n",
            "| epoch  73 |    12/   23 batches |lr 0.000118 | ms/batch 34.37 | loss 0.00672 | ppl     1.01\n",
            "| epoch  73 |    16/   23 batches |lr 0.000118 | ms/batch 34.42 | loss 0.01033 | ppl     1.01\n",
            "| epoch  73 |    20/   23 batches |lr 0.000118 | ms/batch 36.50 | loss 0.01550 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time:  0.88s | valid loss 1.42501 | valid ppl     4.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |     4/   23 batches |lr 0.000112 | ms/batch 43.69 | loss 0.04370 | ppl     1.04\n",
            "| epoch  74 |     8/   23 batches |lr 0.000112 | ms/batch 34.44 | loss 0.01409 | ppl     1.01\n",
            "| epoch  74 |    12/   23 batches |lr 0.000112 | ms/batch 34.53 | loss 0.00674 | ppl     1.01\n",
            "| epoch  74 |    16/   23 batches |lr 0.000112 | ms/batch 35.19 | loss 0.00968 | ppl     1.01\n",
            "| epoch  74 |    20/   23 batches |lr 0.000112 | ms/batch 34.12 | loss 0.01486 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time:  0.87s | valid loss 1.42880 | valid ppl     4.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |     4/   23 batches |lr 0.000107 | ms/batch 44.23 | loss 0.04038 | ppl     1.04\n",
            "| epoch  75 |     8/   23 batches |lr 0.000107 | ms/batch 34.08 | loss 0.01439 | ppl     1.01\n",
            "| epoch  75 |    12/   23 batches |lr 0.000107 | ms/batch 33.94 | loss 0.00635 | ppl     1.01\n",
            "| epoch  75 |    16/   23 batches |lr 0.000107 | ms/batch 34.38 | loss 0.00958 | ppl     1.01\n",
            "| epoch  75 |    20/   23 batches |lr 0.000107 | ms/batch 34.29 | loss 0.01512 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time:  0.86s | valid loss 1.42203 | valid ppl     4.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |     4/   23 batches |lr 0.000101 | ms/batch 43.26 | loss 0.03927 | ppl     1.04\n",
            "| epoch  76 |     8/   23 batches |lr 0.000101 | ms/batch 34.40 | loss 0.01263 | ppl     1.01\n",
            "| epoch  76 |    12/   23 batches |lr 0.000101 | ms/batch 34.16 | loss 0.00680 | ppl     1.01\n",
            "| epoch  76 |    16/   23 batches |lr 0.000101 | ms/batch 34.43 | loss 0.00966 | ppl     1.01\n",
            "| epoch  76 |    20/   23 batches |lr 0.000101 | ms/batch 34.21 | loss 0.01452 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time:  0.86s | valid loss 1.41644 | valid ppl     4.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |     4/   23 batches |lr 0.000096 | ms/batch 44.64 | loss 0.03859 | ppl     1.04\n",
            "| epoch  77 |     8/   23 batches |lr 0.000096 | ms/batch 33.95 | loss 0.01391 | ppl     1.01\n",
            "| epoch  77 |    12/   23 batches |lr 0.000096 | ms/batch 34.05 | loss 0.00610 | ppl     1.01\n",
            "| epoch  77 |    16/   23 batches |lr 0.000096 | ms/batch 34.29 | loss 0.00963 | ppl     1.01\n",
            "| epoch  77 |    20/   23 batches |lr 0.000096 | ms/batch 35.10 | loss 0.01503 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time:  0.86s | valid loss 1.41828 | valid ppl     4.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |     4/   23 batches |lr 0.000091 | ms/batch 45.05 | loss 0.03826 | ppl     1.04\n",
            "| epoch  78 |     8/   23 batches |lr 0.000091 | ms/batch 35.83 | loss 0.01373 | ppl     1.01\n",
            "| epoch  78 |    12/   23 batches |lr 0.000091 | ms/batch 35.77 | loss 0.00614 | ppl     1.01\n",
            "| epoch  78 |    16/   23 batches |lr 0.000091 | ms/batch 35.80 | loss 0.00931 | ppl     1.01\n",
            "| epoch  78 |    20/   23 batches |lr 0.000091 | ms/batch 36.02 | loss 0.01341 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time:  0.90s | valid loss 1.40949 | valid ppl     4.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |     4/   23 batches |lr 0.000087 | ms/batch 47.63 | loss 0.03853 | ppl     1.04\n",
            "| epoch  79 |     8/   23 batches |lr 0.000087 | ms/batch 36.24 | loss 0.01348 | ppl     1.01\n",
            "| epoch  79 |    12/   23 batches |lr 0.000087 | ms/batch 35.28 | loss 0.00719 | ppl     1.01\n",
            "| epoch  79 |    16/   23 batches |lr 0.000087 | ms/batch 34.11 | loss 0.00966 | ppl     1.01\n",
            "| epoch  79 |    20/   23 batches |lr 0.000087 | ms/batch 34.30 | loss 0.01514 | ppl     1.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time:  0.89s | valid loss 1.40613 | valid ppl     4.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |     4/   23 batches |lr 0.000083 | ms/batch 43.61 | loss 0.04014 | ppl     1.04\n",
            "| epoch  80 |     8/   23 batches |lr 0.000083 | ms/batch 35.20 | loss 0.01342 | ppl     1.01\n",
            "| epoch  80 |    12/   23 batches |lr 0.000083 | ms/batch 34.24 | loss 0.00637 | ppl     1.01\n",
            "| epoch  80 |    16/   23 batches |lr 0.000083 | ms/batch 34.48 | loss 0.00958 | ppl     1.01\n",
            "| epoch  80 |    20/   23 batches |lr 0.000083 | ms/batch 34.22 | loss 0.01420 | ppl     1.01\n",
            "tensor([0.3004, 0.2976, 0.2960, 0.2942, 0.2981, 0.2918, 0.2904, 0.3036, 0.3024,\n",
            "        0.3023, 0.3011, 0.3052, 0.3071, 0.3300, 0.3427, 0.3407, 0.3393, 0.3518,\n",
            "        0.3597, 0.3676, 0.3724, 0.3732, 0.3834, 0.3916, 0.3973, 0.4053, 0.4179,\n",
            "        0.4223, 0.4261, 0.4263, 0.4352, 0.4429, 0.4394, 0.4461, 0.4540, 0.4524,\n",
            "        0.4543, 0.4614, 0.4770, 0.4820, 0.4821, 0.4870, 0.4828, 0.4825, 0.4898,\n",
            "        0.4942, 0.4963, 0.5005, 0.5068, 0.5110, 0.5128, 0.5184, 0.5169, 0.5172,\n",
            "        0.5237, 0.5325, 0.6005, 0.6052, 0.6194, 0.6194, 0.6103, 0.5775, 0.6307,\n",
            "        0.6343, 0.6420, 0.6426, 0.6466, 0.6465, 0.6646, 0.6789, 0.6804, 0.6804,\n",
            "        0.6786, 0.6839, 0.6870, 0.6882, 0.6933, 0.7020, 0.7050, 0.7040, 0.6998,\n",
            "        0.6965, 0.6293, 0.6302, 0.6315, 0.6288, 0.6253, 0.6279, 0.6303, 0.6223,\n",
            "        0.6052, 0.5920, 0.6148, 0.6152, 0.6068, 0.5955, 0.6114, 0.6115, 0.5963,\n",
            "        0.5802, 0.5785, 0.5763, 0.5731, 0.5694, 0.5669, 0.5664, 0.5686, 0.5770,\n",
            "        0.5765, 0.5632, 0.5631, 0.5630, 0.5647, 0.5850, 0.6296, 0.6260, 0.6279,\n",
            "        0.6226, 0.6314, 0.6265, 0.6043, 0.5820, 0.5752, 0.5732, 0.5687, 0.5584,\n",
            "        0.5415, 0.5355, 0.4942, 0.4730, 0.4604, 0.5572, 0.5781, 0.5609, 0.6233,\n",
            "        0.6312, 0.6196, 0.5923, 0.5881, 0.6112, 0.6012, 0.5482, 0.5148, 0.4914,\n",
            "        0.4740, 0.4939, 0.4737, 0.4760, 0.4694, 0.5533, 0.5467, 0.5671, 0.5692,\n",
            "        0.5720, 0.5688, 0.5687, 0.5576, 0.5381, 0.5567, 0.5522, 0.5591, 0.5714,\n",
            "        0.5808, 0.5893, 0.5850, 0.5926, 0.5892, 0.5902, 0.6072, 0.6065])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time:  1.53s | valid loss 1.42322 | valid ppl     4.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  81 |     4/   23 batches |lr 0.000078 | ms/batch 42.43 | loss 0.03897 | ppl     1.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  81 |     8/   23 batches |lr 0.000078 | ms/batch 34.60 | loss 0.01324 | ppl     1.01\n",
            "| epoch  81 |    12/   23 batches |lr 0.000078 | ms/batch 35.05 | loss 0.00664 | ppl     1.01\n",
            "| epoch  81 |    16/   23 batches |lr 0.000078 | ms/batch 34.73 | loss 0.00863 | ppl     1.01\n",
            "| epoch  81 |    20/   23 batches |lr 0.000078 | ms/batch 34.22 | loss 0.01385 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time:  0.86s | valid loss 1.40322 | valid ppl     4.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |     4/   23 batches |lr 0.000075 | ms/batch 46.19 | loss 0.03703 | ppl     1.04\n",
            "| epoch  82 |     8/   23 batches |lr 0.000075 | ms/batch 34.80 | loss 0.01399 | ppl     1.01\n",
            "| epoch  82 |    12/   23 batches |lr 0.000075 | ms/batch 33.98 | loss 0.00649 | ppl     1.01\n",
            "| epoch  82 |    16/   23 batches |lr 0.000075 | ms/batch 34.50 | loss 0.00922 | ppl     1.01\n",
            "| epoch  82 |    20/   23 batches |lr 0.000075 | ms/batch 34.13 | loss 0.01310 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time:  0.87s | valid loss 1.39803 | valid ppl     4.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |     4/   23 batches |lr 0.000071 | ms/batch 43.94 | loss 0.03582 | ppl     1.04\n",
            "| epoch  83 |     8/   23 batches |lr 0.000071 | ms/batch 33.88 | loss 0.01232 | ppl     1.01\n",
            "| epoch  83 |    12/   23 batches |lr 0.000071 | ms/batch 34.29 | loss 0.00589 | ppl     1.01\n",
            "| epoch  83 |    16/   23 batches |lr 0.000071 | ms/batch 34.74 | loss 0.00987 | ppl     1.01\n",
            "| epoch  83 |    20/   23 batches |lr 0.000071 | ms/batch 33.95 | loss 0.01356 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time:  0.86s | valid loss 1.39520 | valid ppl     4.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |     4/   23 batches |lr 0.000067 | ms/batch 44.40 | loss 0.03703 | ppl     1.04\n",
            "| epoch  84 |     8/   23 batches |lr 0.000067 | ms/batch 35.11 | loss 0.01262 | ppl     1.01\n",
            "| epoch  84 |    12/   23 batches |lr 0.000067 | ms/batch 34.40 | loss 0.00676 | ppl     1.01\n",
            "| epoch  84 |    16/   23 batches |lr 0.000067 | ms/batch 34.32 | loss 0.00911 | ppl     1.01\n",
            "| epoch  84 |    20/   23 batches |lr 0.000067 | ms/batch 34.07 | loss 0.01324 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time:  0.87s | valid loss 1.39097 | valid ppl     4.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |     4/   23 batches |lr 0.000064 | ms/batch 44.49 | loss 0.03931 | ppl     1.04\n",
            "| epoch  85 |     8/   23 batches |lr 0.000064 | ms/batch 33.92 | loss 0.01300 | ppl     1.01\n",
            "| epoch  85 |    12/   23 batches |lr 0.000064 | ms/batch 34.24 | loss 0.00588 | ppl     1.01\n",
            "| epoch  85 |    16/   23 batches |lr 0.000064 | ms/batch 34.24 | loss 0.00891 | ppl     1.01\n",
            "| epoch  85 |    20/   23 batches |lr 0.000064 | ms/batch 36.37 | loss 0.01330 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time:  0.88s | valid loss 1.38743 | valid ppl     4.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |     4/   23 batches |lr 0.000061 | ms/batch 45.93 | loss 0.04220 | ppl     1.04\n",
            "| epoch  86 |     8/   23 batches |lr 0.000061 | ms/batch 35.94 | loss 0.01195 | ppl     1.01\n",
            "| epoch  86 |    12/   23 batches |lr 0.000061 | ms/batch 35.96 | loss 0.00581 | ppl     1.01\n",
            "| epoch  86 |    16/   23 batches |lr 0.000061 | ms/batch 33.83 | loss 0.00941 | ppl     1.01\n",
            "| epoch  86 |    20/   23 batches |lr 0.000061 | ms/batch 34.50 | loss 0.01274 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time:  0.88s | valid loss 1.39038 | valid ppl     4.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |     4/   23 batches |lr 0.000058 | ms/batch 43.76 | loss 0.03582 | ppl     1.04\n",
            "| epoch  87 |     8/   23 batches |lr 0.000058 | ms/batch 33.87 | loss 0.01324 | ppl     1.01\n",
            "| epoch  87 |    12/   23 batches |lr 0.000058 | ms/batch 34.13 | loss 0.00652 | ppl     1.01\n",
            "| epoch  87 |    16/   23 batches |lr 0.000058 | ms/batch 35.01 | loss 0.01024 | ppl     1.01\n",
            "| epoch  87 |    20/   23 batches |lr 0.000058 | ms/batch 34.67 | loss 0.01294 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time:  0.86s | valid loss 1.38777 | valid ppl     4.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |     4/   23 batches |lr 0.000055 | ms/batch 46.30 | loss 0.03736 | ppl     1.04\n",
            "| epoch  88 |     8/   23 batches |lr 0.000055 | ms/batch 35.62 | loss 0.01280 | ppl     1.01\n",
            "| epoch  88 |    12/   23 batches |lr 0.000055 | ms/batch 33.83 | loss 0.00651 | ppl     1.01\n",
            "| epoch  88 |    16/   23 batches |lr 0.000055 | ms/batch 34.60 | loss 0.00857 | ppl     1.01\n",
            "| epoch  88 |    20/   23 batches |lr 0.000055 | ms/batch 34.98 | loss 0.01337 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time:  0.88s | valid loss 1.38376 | valid ppl     3.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |     4/   23 batches |lr 0.000052 | ms/batch 45.97 | loss 0.03689 | ppl     1.04\n",
            "| epoch  89 |     8/   23 batches |lr 0.000052 | ms/batch 36.34 | loss 0.01204 | ppl     1.01\n",
            "| epoch  89 |    12/   23 batches |lr 0.000052 | ms/batch 36.08 | loss 0.00628 | ppl     1.01\n",
            "| epoch  89 |    16/   23 batches |lr 0.000052 | ms/batch 36.36 | loss 0.00943 | ppl     1.01\n",
            "| epoch  89 |    20/   23 batches |lr 0.000052 | ms/batch 35.99 | loss 0.01328 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time:  0.90s | valid loss 1.37828 | valid ppl     3.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |     4/   23 batches |lr 0.000049 | ms/batch 45.65 | loss 0.03610 | ppl     1.04\n",
            "| epoch  90 |     8/   23 batches |lr 0.000049 | ms/batch 34.01 | loss 0.01283 | ppl     1.01\n",
            "| epoch  90 |    12/   23 batches |lr 0.000049 | ms/batch 34.37 | loss 0.00582 | ppl     1.01\n",
            "| epoch  90 |    16/   23 batches |lr 0.000049 | ms/batch 34.84 | loss 0.00877 | ppl     1.01\n",
            "| epoch  90 |    20/   23 batches |lr 0.000049 | ms/batch 34.98 | loss 0.01285 | ppl     1.01\n",
            "tensor([0.3037, 0.3007, 0.2993, 0.2964, 0.2989, 0.2919, 0.2939, 0.3053, 0.3046,\n",
            "        0.3049, 0.3034, 0.3072, 0.3118, 0.3329, 0.3470, 0.3446, 0.3437, 0.3558,\n",
            "        0.3634, 0.3710, 0.3764, 0.3766, 0.3866, 0.3943, 0.4002, 0.4087, 0.4228,\n",
            "        0.4269, 0.4317, 0.4310, 0.4400, 0.4492, 0.4452, 0.4521, 0.4595, 0.4585,\n",
            "        0.4602, 0.4677, 0.4844, 0.4907, 0.4895, 0.4935, 0.4909, 0.4894, 0.4963,\n",
            "        0.5012, 0.5040, 0.5087, 0.5149, 0.5180, 0.5195, 0.5247, 0.5226, 0.5241,\n",
            "        0.5314, 0.5390, 0.6076, 0.6133, 0.6265, 0.6262, 0.6092, 0.5726, 0.6380,\n",
            "        0.6400, 0.6501, 0.6504, 0.6538, 0.6535, 0.6774, 0.6873, 0.6882, 0.6883,\n",
            "        0.6860, 0.6912, 0.6947, 0.6963, 0.7023, 0.7110, 0.7139, 0.7124, 0.7082,\n",
            "        0.7052, 0.6407, 0.6412, 0.6426, 0.6415, 0.6389, 0.6416, 0.6444, 0.6362,\n",
            "        0.6180, 0.6116, 0.6290, 0.6268, 0.6230, 0.6167, 0.6254, 0.6258, 0.6191,\n",
            "        0.5919, 0.5880, 0.5855, 0.5821, 0.5785, 0.5764, 0.5751, 0.5769, 0.5853,\n",
            "        0.5848, 0.5716, 0.5726, 0.5719, 0.5733, 0.5950, 0.6402, 0.6365, 0.6383,\n",
            "        0.6325, 0.6417, 0.6352, 0.6162, 0.5918, 0.5888, 0.5846, 0.5771, 0.5667,\n",
            "        0.5469, 0.5253, 0.4940, 0.4801, 0.4650, 0.5477, 0.5948, 0.5741, 0.6384,\n",
            "        0.6437, 0.6298, 0.6022, 0.6008, 0.6262, 0.6140, 0.5662, 0.5317, 0.5044,\n",
            "        0.4910, 0.5097, 0.4903, 0.4920, 0.4846, 0.5776, 0.5718, 0.5893, 0.5902,\n",
            "        0.5923, 0.5894, 0.5893, 0.5809, 0.5596, 0.5786, 0.5776, 0.5813, 0.5925,\n",
            "        0.6012, 0.6081, 0.6035, 0.6114, 0.6077, 0.6103, 0.6257, 0.6260])\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time:  1.64s | valid loss 1.39777 | valid ppl     4.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  91 |     4/   23 batches |lr 0.000047 | ms/batch 42.78 | loss 0.03596 | ppl     1.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  91 |     8/   23 batches |lr 0.000047 | ms/batch 34.44 | loss 0.01171 | ppl     1.01\n",
            "| epoch  91 |    12/   23 batches |lr 0.000047 | ms/batch 34.33 | loss 0.00592 | ppl     1.01\n",
            "| epoch  91 |    16/   23 batches |lr 0.000047 | ms/batch 34.91 | loss 0.00921 | ppl     1.01\n",
            "| epoch  91 |    20/   23 batches |lr 0.000047 | ms/batch 36.35 | loss 0.01263 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time:  0.87s | valid loss 1.38354 | valid ppl     3.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |     4/   23 batches |lr 0.000045 | ms/batch 46.24 | loss 0.03831 | ppl     1.04\n",
            "| epoch  92 |     8/   23 batches |lr 0.000045 | ms/batch 35.06 | loss 0.01229 | ppl     1.01\n",
            "| epoch  92 |    12/   23 batches |lr 0.000045 | ms/batch 34.44 | loss 0.00624 | ppl     1.01\n",
            "| epoch  92 |    16/   23 batches |lr 0.000045 | ms/batch 35.13 | loss 0.00854 | ppl     1.01\n",
            "| epoch  92 |    20/   23 batches |lr 0.000045 | ms/batch 34.73 | loss 0.01318 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time:  0.88s | valid loss 1.38242 | valid ppl     3.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |     4/   23 batches |lr 0.000042 | ms/batch 44.42 | loss 0.03850 | ppl     1.04\n",
            "| epoch  93 |     8/   23 batches |lr 0.000042 | ms/batch 34.79 | loss 0.01128 | ppl     1.01\n",
            "| epoch  93 |    12/   23 batches |lr 0.000042 | ms/batch 34.21 | loss 0.00593 | ppl     1.01\n",
            "| epoch  93 |    16/   23 batches |lr 0.000042 | ms/batch 34.56 | loss 0.00925 | ppl     1.01\n",
            "| epoch  93 |    20/   23 batches |lr 0.000042 | ms/batch 34.45 | loss 0.01333 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time:  0.86s | valid loss 1.38162 | valid ppl     3.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |     4/   23 batches |lr 0.000040 | ms/batch 43.89 | loss 0.03767 | ppl     1.04\n",
            "| epoch  94 |     8/   23 batches |lr 0.000040 | ms/batch 34.17 | loss 0.01166 | ppl     1.01\n",
            "| epoch  94 |    12/   23 batches |lr 0.000040 | ms/batch 34.07 | loss 0.00566 | ppl     1.01\n",
            "| epoch  94 |    16/   23 batches |lr 0.000040 | ms/batch 34.56 | loss 0.00894 | ppl     1.01\n",
            "| epoch  94 |    20/   23 batches |lr 0.000040 | ms/batch 34.20 | loss 0.01171 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time:  0.86s | valid loss 1.37612 | valid ppl     3.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |     4/   23 batches |lr 0.000038 | ms/batch 43.88 | loss 0.03737 | ppl     1.04\n",
            "| epoch  95 |     8/   23 batches |lr 0.000038 | ms/batch 34.42 | loss 0.01202 | ppl     1.01\n",
            "| epoch  95 |    12/   23 batches |lr 0.000038 | ms/batch 33.92 | loss 0.00622 | ppl     1.01\n",
            "| epoch  95 |    16/   23 batches |lr 0.000038 | ms/batch 34.60 | loss 0.00940 | ppl     1.01\n",
            "| epoch  95 |    20/   23 batches |lr 0.000038 | ms/batch 34.09 | loss 0.01294 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time:  0.86s | valid loss 1.37394 | valid ppl     3.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |     4/   23 batches |lr 0.000036 | ms/batch 46.27 | loss 0.03674 | ppl     1.04\n",
            "| epoch  96 |     8/   23 batches |lr 0.000036 | ms/batch 35.81 | loss 0.01236 | ppl     1.01\n",
            "| epoch  96 |    12/   23 batches |lr 0.000036 | ms/batch 36.11 | loss 0.00599 | ppl     1.01\n",
            "| epoch  96 |    16/   23 batches |lr 0.000036 | ms/batch 35.97 | loss 0.00912 | ppl     1.01\n",
            "| epoch  96 |    20/   23 batches |lr 0.000036 | ms/batch 36.11 | loss 0.01291 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time:  0.91s | valid loss 1.37328 | valid ppl     3.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |     4/   23 batches |lr 0.000035 | ms/batch 44.63 | loss 0.03590 | ppl     1.04\n",
            "| epoch  97 |     8/   23 batches |lr 0.000035 | ms/batch 35.17 | loss 0.01171 | ppl     1.01\n",
            "| epoch  97 |    12/   23 batches |lr 0.000035 | ms/batch 35.64 | loss 0.00616 | ppl     1.01\n",
            "| epoch  97 |    16/   23 batches |lr 0.000035 | ms/batch 36.01 | loss 0.00874 | ppl     1.01\n",
            "| epoch  97 |    20/   23 batches |lr 0.000035 | ms/batch 35.98 | loss 0.01213 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time:  0.89s | valid loss 1.37223 | valid ppl     3.94\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |     4/   23 batches |lr 0.000033 | ms/batch 45.29 | loss 0.03324 | ppl     1.03\n",
            "| epoch  98 |     8/   23 batches |lr 0.000033 | ms/batch 34.68 | loss 0.01296 | ppl     1.01\n",
            "| epoch  98 |    12/   23 batches |lr 0.000033 | ms/batch 33.83 | loss 0.00573 | ppl     1.01\n",
            "| epoch  98 |    16/   23 batches |lr 0.000033 | ms/batch 34.79 | loss 0.00829 | ppl     1.01\n",
            "| epoch  98 |    20/   23 batches |lr 0.000033 | ms/batch 34.20 | loss 0.01287 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time:  0.87s | valid loss 1.37478 | valid ppl     3.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |     4/   23 batches |lr 0.000031 | ms/batch 43.54 | loss 0.03885 | ppl     1.04\n",
            "| epoch  99 |     8/   23 batches |lr 0.000031 | ms/batch 34.38 | loss 0.01281 | ppl     1.01\n",
            "| epoch  99 |    12/   23 batches |lr 0.000031 | ms/batch 34.36 | loss 0.00603 | ppl     1.01\n",
            "| epoch  99 |    16/   23 batches |lr 0.000031 | ms/batch 34.41 | loss 0.00870 | ppl     1.01\n",
            "| epoch  99 |    20/   23 batches |lr 0.000031 | ms/batch 34.53 | loss 0.01302 | ppl     1.01\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time:  0.86s | valid loss 1.37676 | valid ppl     3.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 100 |     4/   23 batches |lr 0.000030 | ms/batch 44.16 | loss 0.03740 | ppl     1.04\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}